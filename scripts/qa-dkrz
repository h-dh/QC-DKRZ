#! /bin/bash

# ##/*! \file qa-DKRZ
## \brief Start script for the QA

## This script starts a Quality Assurance (QA) session.\n
## The script is started on the command-line with optional parameters.\n
## Example: <tt> path/QA-DKRZ/scripts/qa-DKRZ -f file.conf [opts] </tt> \n
## The script keeps track of netCDF files scheduled for processing
## (and those which have been processed). A quality check is performed
## by an executable of the \a qA_main.cpp file within
## the script \a qaExecutable_FS which in turn was launched by
## \a qa-DKRZ asynchronously parallel in the back-ground.
## User provided parameters from a configuration and/or task
## file as well as from the command-line are parsed by the
## script \a qaConfiguration.\n
##*/

##//! Apply rules for SELECTing and LOCKing of paths and files.
#
##/*! Syntax Rules of SELECT / LOCK ( [] indicates optional):\n
## <tt>SELECT [path1[, path2, ...] = ] [var1[, var2, ...]]</tt>\n
## SELECT/LOCK has a special syntax (with [] indicating optional):\n
## Note: '=' has a special meaning; mulitple assignments just add.
## Same for LOCK.

## A path is a sub-path appended to the tree given by PROJECT_DATA.
## Several SELECT and LOCK statements, respectively, are cumulative.
## There must be no assignment character '=' following key-words
## or SELECT or LOCK.
## Each variable specification is applied to all paths.\n
## Assignments may contain (and usually do) regular expressions.
## The rules of the RegExp must be those of the 'expr' command explained
## in 'man  grep'.
## This implies that each regExpr must begin from the first character
## with the caret ^ omitted. E.g. SELECT .* /historical /.* /Amon =
## Omitting path and variable defaults to all, respectively, i.e. '.*'\n
## Important: selecting one or more paths requires a '=' character behind
## the last path. Otherwise, it is taken as selection for variables.
## SELECT := starts a multiple line selection (same rules as for multiple
## line assignment).\n
## Same for LOCK. Multiple lines SELECTions may be mixed
## with such given by a single line.\n
## Note: SELECT in a config-file and via command-line option '-S arg'
## are combined; arg (without key-word SELECT) is as a single-line.\n
## Examples: \n
## SELECT path=var # specifies a single path where to look for a single ## variable \n
## SELECT p1,p2=var  #  two paths to look for a variable \n
## SELECT p1,p2=  #  two paths with every variable, equivalent to #p1,p2=.*  \n
## SELECT p1=v1,v2  #   one path with two variables \n
## SELECT var[,v2,v3]  #   looks for variables in the entire DRS tree \n
## SELECT p1=,p2=v1...  --> error,  SELECT  p1,p2=v1...  --> ok. \n
##*/

applyRules()
{
   # return 0 :: true

   local retVal
   retVal=1  # go for a file
   local f

   # Is there a race condition? Yes? Then wait.
   if [ ${PROC_POOL} ] ; then
     for f in $(ls ${PROC_POOL}/experiments/* 2> /dev/null) ; do
       if expr match "$f" ".*:${1}" &> /dev/null; then
         # the filename root matched. But, is it also the right path?
         # a race condition can also happen here in the pipe-line
         local tp
         tp="$( cat $f 2> /dev/null | head -n 3 | tail -n 1)"
         if [ ${tp} ] ; then
           tp=${tp#SUB_PATH=}
           test "$tp" != "${subPath}" && break  # is different
         fi

         return 0
       fi
     done
   fi

   if applySelectionRules $1 ; then
     return 0  # not selected
   fi

   if applyLockRules $1 ; then
     retVal=0  # not selected
   fi

   return $retVal
}

applyLockRules()
{
  # return 0, if locked
  # return 1, if not

  local refName pl sP
  refName=$1

  sP=${subPath}
  test ! ${sP} && sP='/.'

  test ${#LOCK_PATH_LIST[*]} -eq 0 -a ${#LOCK_VAR_LIST[*]} -eq 0  && return 1

  # any path selected?
  for(( pl=0 ;  $pl < ${#LOCK_PATH_LIST[*]} ; ++pl )) ; do
    if expr match ${sP} "${LOCK_PATH_LIST[pl]}" &> /dev/null ; then
      if expr match ${refName} "${LOCK_VAR_LIST[pl]}" &> /dev/null ; then
        return 0
      fi
    fi
  done

  return 1  # no locks found
}

applySelectionRules()
{
  # return 1, if selected
  # return 0, if not

  local refName pl sP
  refName=$1

  sP=${subPath}
  test ! ${sP} && sP='.'

  test ${#SELECT_PATH_LIST[*]} -eq 0 -a ${#SELECT_VAR_LIST[*]} -eq 0 && return 1

  # any path selected?
  for(( pl=0 ;  $pl < ${#SELECT_PATH_LIST[*]} ; ++pl )) ; do
    if expr match ${sP} "${SELECT_PATH_LIST[pl]}" &> /dev/null ; then
      # special: only the path is to be tested
      test "$1" = PATH && return 1

      # if no variable was selected, then all variables match
      if expr match ${refName} "${SELECT_VAR_LIST[pl]}" &> /dev/null ; then
        return 1
      fi
    fi
  done

  return 0  # no selection for the current sub-path
}

bind_checksum()
{
  local fs
  fs=( ${*##*/} ) # just the filename

  local type

  # extension corresponding to the checksum method
  cs_ext=md5

  if [ "${CHECKSUM}" = t ] ; then
    type='--type=md5'
  else
    cs_ext=${CHECKSUM%sum}
    cs_ext=${cs_ext##*/}
    type="--type=${CHECKSUM}"
  fi

  if [ ${CS_DIR} ] ; then
    if [ ${CS_DIR:0:1} = '/' ] ; then
      CS_TABLE="${CS_DIR}"
    else
      CS_TABLE="${QA_RESULTS}/${CS_DIR}"
    fi
  else
    test ${CS_STAND_ALONE:-f} = f && CS_TABLE="${QA_RESULTS}/cs_table"
  fi

  if [ ${CS_STAND_ALONE:-f} = t ] ; then
    if [ ! ${CS_TABLE} ] ; then
      CS_TABLE=${QA_RESULTS}/data/${subPath}
    fi
  fi

  local email
  if [ ${EMAIL_TO[0]} ] ; then
     email="${EMAIL_TO[*]}"
     email="-m ${email// /,}"
  fi

  if [ ${#EXP_PATH_INDEX[*]} -gt 0 ] ; then
    getExperimentName ${subPath}
  else
    getExperimentName ${fs[0]}
  fi

  # calculate the checksum(s)
  ${QA_SRC}/scripts/checkSum -b ${QA_BIN#*:} $type \
      -q ${QA_RESULTS} ${YAML:+--yaml} ${CS_NO_HISTORY:+--no_history} \
      ${CS_STAND_ALONE:+-w}  $email ${CS_TABLE:+-t} ${CS_TABLE} \
      ${CURR_EXP_NAME:+-x} ${CURR_EXP_NAME} \
      -P ${PROJECT_DATA} -S ${subPath} ${fs[*]}

  return $?
}

callPing()
{
  # no ping necessary
  test "$1" == "$HOSTNAME" && return 0

  if [ ${PING_ENABLED:-f} = t ] ; then
    if $myPing -c 1 $1 &> /dev/null ; then
      return 0
    fi
  fi

  return 1
}

##//! User provided configuration setting from file and command-line.

##/*!
## Detailed comments on configuration parameters are given in files
## \a path/QA-DKRZ/tables/projects/*_qa.conf
##*/

callQaConfig()
{
# setting defaults, parsing of the configuration file and command-line  is left to the
# qaConfiguration, which returns key-word assignments and lists.
# NOTE: arrays of experiments and parameters are provided by the file
# LOGIDR/cache_request.txt.

  local items i key

# necessary for returning embedded arrays from qaConfiguration
  OLD_IFS="$IFS"
  IFS="%"

#  set -f

# calling the configuration script
  local p=${0%/*}/
  test ${p} = ${0} && p=

  if ! items=( $( ${p}$QA_CONFIG $* ) ) ; then
    # not necessarily an error; also SHOW_CONF, CHECK_TOOLS and
    # no argument for displaying help will return exit 1
    exit
  fi


  IFS="$OLD_IFS"

  if [ ! ${items[0]} ] ; then
    std_out flush "nothing configured, nothing to do.\nabnormal termination."
    lastStatus=1  # exit status of this script
    exit
  fi

  #enable settings for the qa
  set -f
  for(( i=0 ; i < ${#items[*]} ; ++i )) ; do
    key="${items[i]%%=*}"

    # very specific: map PROJECT_DATA --> PROJECT_DATAV
    test ${key} = PROJECT_DATA && key=${key}V

    # any SHOW_... directive?
    test ${key:0:4} = SHOW && isShow=t

    if [ "${items[i]}" = "${items[i]// /}" ] ; then
      eval ${key}="${items[i]#*=}"
    else
      eval ${key}=\("${items[i]#*=}"\)
    fi

    # collection of variable names for tables
    test ${key%%_*} = TABLE && tableVars[${#tableVars[*]}]=${key%=*}

    setKWL ${key}
  done
  set +f

# invoked by option -E_DEBUG_MANAGER
  if [ ${#DEBUG_MANAGER} -gt 1 ] ; then
    exec 7<&2
    dbgCycle=0
    exec 2>${DEBUG_MANAGER}.$dbgCycle
    set -x
  elif [ ${DEBUG_MANAGER:-f} = t ] ; then
    set -x
  fi

  if [ ${DEBUG_X} ] ; then
    # debug-mode for external scripts
    if [ ${DEBUG_X} = t ] ; then
      DEBUG_X=--debug
    else
      DEBUG_X="--debug=${DEBUG_X}"
    fi
  fi

  test ${RESUME_SESSION:-f} = t && log_sessMessage "session resumed."

  test ${EXP_PATH_INDEX:-f} = f && DISABLE_CONSISTENCY_CHECK=t

  # always set
  PATH=${QA_BIN#*:}:$PATH

  #save for NIGHT_SHIFT operation
  save_QA_EXEC_HOSTS=( ${QA_EXEC_HOSTS[*]} )
  save_NUM_EXEC_THREADS=( ${NUM_EXEC_THREADS[*]} )

  QA_DATADIR=${QA_RESULTS}/data

#  set +f

  if [ "${SHOW_CLEAR}" -a "${SHOW_CLEAR}" != t ] ; then
    # SHOW_CLEAR may contain same assignment than CLEAR itself
    test ! ${CLEAR} && CLEAR=${SHOW_CLEAR}
    SHOW_CLEAR=t
  fi

  return
}

##//! Launcher of the executable of QA main-program qA_main.cpp

##/*!
## The script runs in the back-round. Hence, multiple instances may
## be proccessed in parallel. The script processes also annotations.
##*/

callQaExecutor()
{
  local nextFile
  local nextPeriod

  local i args item keyW w

  # this is the ultimative test (and unnecessary)
  test $# -eq 0 && return

  local EXP_NAME=$CURR_EXP_NAME

  nextFile=$1
  nextPeriod=$( getDateRange $nextFile )

  # Create semaphore file.
  local str
  str=${nextFile%.nc}

  local DT
  DT=$( date +'%F_%T' )

  # with next identification number
  procFile=$PROC_POOL/"${nextHost%%.*}:${str}_$((++EX_ID)).txt"

  local text
  text="NEXT_FILE=${nextFile}"

  test ${nextPeriod} \
      && text="${text}\nNEXT_PERIOD=${nextPeriod}"
  test ${subPath} \
      && text="${text}\nSUB_PATH=${subPath}"

  # 'export' the terminal device
  test -c "$TTY" && text="${text}\nTTY=${TTY}"

#  log_sessMessage \
#    "${nextHost%%.*}: ${subPath}/${nextFile}: start"

  local k
  k=0 # index for optional keyW items

  # key-words with assignment for the executor
  keyW=( ${keyW[*]} \
          APPLY_MAXIMUM_DATE_RANGE \
          ARITHMETIC_MEAN \
          CF \
          CF_FOLLOW_RECOMMENDATIONS \
          CF_NOTE \
          CF_NOTE_ALWAYS \
          CF_NOTE_LEVEL_LIMIT \
          CHECK_MODE \
          CHECKSUM \
          CS_STAND_ALONE \
          CS_TABLE \
          DATA_IN_PRODUCTION \
          DISABLE_INF_NAN \
          DISABLE_TIME_BOUNDS_CHECK \
          EMAIL_TO \
          EXCLUDE_ATTRIBUTE \
          EXCLUDE_VARIABLE \
          EXP_LOGDIR \
          EXP_NAME \
          FD_BARS \
          FD_EXPLICIT_PROPS \
          FD_PLAIN \
          FD_PROPERTY_PATH \
          FD_TIME_PART \
          FILE_SEQUENCE \
          FREQ_DIST \
          FREQUENCY \
          FREQUENCY_POSITION \
          HLEVD \
          HLEVD_DELETE_FILE \
          HLEVD_DETREND \
          HLEVD_KEEP_THRESHOLD_FILE \
          HLEVD_THRESHOLD \
          IMPORTED_PATH \
          IGNORE_REFERENCE_DATE \
          IGNORE_REF_DATE_ACROSS_EXP \
          LOG_CPU_TIME \
          MAIL \
          NEVER_BREAK_SESSION \
          NEXT_RECORDS \
          NICE \
          NIGHT_SHIFT \
          NON_REGULAR_TIME_STEP \
          NOTE \
          NOTE_ALWAYS \
          NOTE_LEVEL_LIMIT \
          OUTLIER_TEST \
          PARENT_EXP_ID \
          PARENT_EXP_RIP \
          PING_ENABLED \
          POST_PROC \
          PRINT_GREP_MARK \
          PROC_POOL \
          PROJECT \
          PROJECT_AS \
          PROJECT_DATA \
          PROJECT_TABLE \
          QA \
          QA_HOST \
          QA_NCFILE_FLAGS \
          QA_RESULTS \
          QA_SRC \
          REATTEMPT_LIMIT \
          REPLICATED_RECORD \
          SESSION \
          SESSION_LOGDIR \
          SHOW_CALL \
          SLEEP_TIME \
          TIME_LIMIT \
          TRACKING_ID_ONLY \
          USE_STRICT \
          WORK_AT_LOW_LOAD \
  )

  keyW=( ${keyW[*]} ${tableVars[*]} )
  i=0

  test ! ${DEBUG_MANAGER} && voidX

  #use keywords and corresponding values to construct file in pool

  for item in ${keyW[*]} ; do
     eval w="\${${item}[*]}"
     test -z "$w" && continue

     text="${text}\n${item}=${w}"
  done
  test ! ${DEBUG_MANAGER} && voidX

  # call qaExecutor with arg-list: format: name=value
  # Note: if execution takes place on a host different than
  # the one where qa-DKRZ runs, then all paths must be
  # accessible.

  local prevPID=$currPID
  local ca
  test ${FLOW_TRACE:-f} = t && ca="FLOW_TRACE=t "
  test ${DEBUG_EXECUTOR:-f} = t && ca="${ca} DEBUG_EXECUTOR=t "

  if [ "$nextHost" = "${HOSTNAME:0:${#nextHost}}" ] ; then
    # use the first item of the QA_BIN array

    text="${text}\nIMPORTED_PATH=${QA_BIN#*:}"
    echo -e "$text" > $procFile

    $QA_SRC/scripts/$QA_FILE_EXECUTER "${ca}QA_SRC=${QA_SRC} PROC_POOL=$PROC_POOL PROC_FILE=${procFile##*/} PAR_PID=${rootPID}" &
  else
    local bin
    for bin in ${QA_BIN[*]} ; do
      if [ "${nextHost}" = ${bin%:*} ] ; then
        text="${text}\nIMPORTED_PATH=${bin#*:}"
        break
      fi
    done


    echo -e "$text" > $procFile

    if callPing ; then
      ssh $nextHost $QA_SRC/scripts/$QA_FILE_EXECUTER "PROC_POOL=$PROC_POOL PROC_FILE=${procFile##*/} PAR_PID=${rootPID} &" &> /dev/null
    fi
  fi

  currPID=$!

  return
}

catFiles()
{
  # check whether at least one of the files to be concatenated is younger
  # than the target. Here, younger means that the time in seconds is higher

  local target=$1
  shift
  local fs=( $* )

  local i sec isNew=f
  declare -a sec

  if [ -f ${target} ] ; then
    local secTarget=$( $QA_SRC/bin/fModTime.x ${target} | awk '{print $6}')

    for(( i=0 ; i < ${#fs[*]} ; ++i )) ; do
       sec[i]=$( $QA_SRC/bin/fModTime.x ${fs[i]} | awk '{print $6}')

       if [ ${sec[i]} -gt ${secTarget} ] ; then
          isNew=t
          break
       fi
    done
  else
    isNew=t
  fi

  if [ ${isNew} = t ] ; then
    cat ${fs[0]} > ${target}

    for(( i=1 ; i < ${#fs[*]} ; ++i )) ; do
      cat ${fs[i]} >> ${target}
    done
  fi

  return
}

##//! Process scheduler
##/*!
## A frame function with life-span over the entire session.
## Keeps track of paths, files and running processes.
##*/

check()
{
  # The sequence of sub-temporal files is stored in a stack, which
  # is processed on after another. This is different to the
  # horizontal approach, when, after having processed the next
  # sub-temp file  of a given variable, the next variable is touched,
  # also only for the very next sub-temporal file.
  # There are a number of stacks corresponding to the number of hosts and
  # threads prescribed in the configuration.
  nFcurr=0
  nFmax=0
  currPID=0
  countActivePipes=0
  waitCounter=0

  local line subPath
  declare -a line

#  set +f

  # save stdin
  exec 9<&0

  # connect file to input;
  # keep it open for reading while more paths may be appended.
  exec 0< ${pathListFile}

  while : ; do

    while : ; do
      # read next sub path from pathListFile, get all variables
      # contained within after having looked for locks.

#trace \
      getNextSubPath

      for(( ix=0 ; ix < ${#fBase[*]} ; ++ix )) ; do

        if \
#trace \
          operatePipes ${subPath} ; then break 3 ; fi

#trace \
        checkClosedMessages
      done
    done

  done

  # restore stdin and free #9
  exec 0<&9 9<&-

  # this is for a wipe out run
  test ${isCLEAR_ONLY:-f} = t && exit

  # don't remove everything done so far in the next looping
  test ${CLEAR} && unset CLEAR

  # Just wait, give the qaExecutor(s) a chance to finish.
  # This does not work for qaExecutor instances launched by ssh.
#trace \
  wait_fnct

  return
}

##//! Finialisation of annotations of each check.

##/*!
## Communication between \a qa-DKRZ and \ qaExecutor is done
## by temporary files. After closing an qaExecutor instance, this
## function finalises annotation processes.
##*/

checkClosedMessages()
{
  # qaExecutors have added locked or closed files for finished runs
  local expName f fs ffs ff g

  fs=( $( ls $PROC_POOL/*.closed 2> /dev/null ) )

  for f in ${fs} ; do
    expName="$( grep EXP_NAME= $f )"
    expName=${expName#EXP_NAME=}

    # experiment log-file
    ffs=( $( ls $PROC_POOL/experiments/$expName.*.log 2> /dev/null ) )
    for ff in ${ffs[*]} ; do
      if \
         tryCom get_status \
         test -s $ff  ; then
         tryCom \
         cat "$ff" >> $EXP_LOGDIR/${expName}.log
         tryCom \
         \rm -f "$ff"

         isAnythingDone=t
      fi
    done

    # logs of qA.x execution time
    if [ ${LOG_CPU_TIME:-f} = t ] ; then
      ffs=( $( ls $PROC_POOL/experiments/$expName.*.time 2> /dev/null ) )
      local line items
      declare -a items
      for ff in ${ffs[*]} ; do
        if \
           tryCom get_status \
           test -s $ff
        then
           # remove obsolete entries, thus we have to read one by one
           while read line ; do
             items=( ${line} )
             if grep -q ${items[3]} $EXP_LOGDIR/${expName}.time &> /dev/null ] ; then
                sed -i "/${items[3]}/d" $EXP_LOGDIR/${expName}.time
             fi

             echo "$line" >> $EXP_LOGDIR/${expName}.time
           done < $ff
           \rm -f "$ff"
        fi
      done
    fi

    # session log-file
    ffs=( $( ls $PROC_POOL/session/$SESSION.*.log 2> /dev/null ) )
    for ff in ${ffs[*]} ; do
      if \
         tryCom get_status \
         test -s $ff  ; then
         cat $ff >> $SESSION_LOGDIR/session.log
         \rm -f "$ff"
      fi
    done

    \rm  $f
  done

  return
}

##//! Look for lock-files preventing processing of a file.

##/*!
## Certain level of annotation cause the creation of a lock-file,
## which inhibits further processing of a given variable.
##*/

checkLockFile()
{
   # return 0 :: true
   # $1 == PATH: check only paths
   # $2        : qa_*.nc file if any

   # any variable locked?
   ls ${QA_RESULTS}/data/${subPath}/*_lock_${1}.txt &> /dev/null
   local x_lock=$?

   if [ ${LOCK_NOTES:-f} = t ] ; then
     ls ${QA_RESULTS}/data/${subPath}/*_note_${1}.txt &> /dev/null
     local x_note=$?
   fi

   if [ ${x_note:-1} -eq 0 -o ${x_lock:-1} -eq 0 ] ; then
     if [ ${IGNORE_LOCK_FILES:-f} = f ] ; then
       return 0 # option says: don't ignore a blocking file
     else
       # option says: ignore blocking file
       if [ ! "${2}" ] ; then
         # no qa-result.nc file; block always
         return 0
       fi
     fi
   fi

   return 1
}

checkValidNcFile()
{
  # Probe corrupt file due to a crash.
  # Return 0, i.e. true, if there is no solution
  local fs p v

  p=$1 # path
  v=$2 # filename name

  tryCom \
  test -d $p

  fs=$( ls $p/z_qa_${v}.nc 2> /dev/null)

  # Any previous backup file available? Yes. Then a crash happened.
  # Restore backup.
  if [ ${fs} ] ; then
    mv $p/z_qa_${v}.nc $p/qa_${v}.nc

    if [ -d $p/Z_fd_${v} ] ; then
      \rm -f $p/fd_${v}*.build
      if ls $p/Z_fd_${v}/* &> /dev/null ; then
        cp $p/Z_fd_${v}/* $p &> /dev/null
      fi
      rmdir $p/Z_fd_${v}/* &> /dev/null
    fi

    return 1
  fi

  # A crash happened while the file was open the first time.
  # No backup is available.
  fs=$( ls $p/qa_${v}.nc 2> /dev/null)

  if [ ${fs} ] ; then
    return 1 # no previous check at all
  fi

  if ! testValidNC.x $fs ; then
    # clear a corrupt file
    \rm -f "$fs"
  fi

  return 1
}

##//! Clear lock-files

##/*!
## Lock-files from a previous session are removed.
##*/

clear()
{
  local f fs t tx ts
  local isFL=f
  local isResume=f
  local isMessage=f

  isClear=t  # global scope

  # arbitrary order of arguments
  for f in ${CLEAR//,/ } ; do
    test ${CLEAR} = t && break  # unconditional

    isClear=f

    if [ "$f" = follow_links ] ; then
       test ${DEREFERENCE_SYM_LINKS:-f} = f && isFL=t
       isClear=t
    elif [ "${f:0:3}" = res ] ; then
       isResume=t
       isClear=t
    elif [ "$f" = only ] ; then
       isCLEAR_ONLY=t
       isClear=t
    elif [ "${f:0:4}" = lock ] ; then
       # locked  files
       if ls ${QA_RESULTS}/data/${subPath}/qa_lock_${fBase[ix]}* &> /dev/null ; then
         isClear=t
       fi
    elif [ "${f:0:4}" = note ] ; then
       # if any note
       if ls ${QA_RESULTS}/data/${subPath}/qa_note*_${fBase[ix]}* &> /dev/null ; then
         isClear=t
       fi
    elif [ "${f:0:4}" = mark ] ; then
       # only pass those that are locked; redo erroneous cases
       if ls ${QA_RESULTS}/data/${subPath}/clear.mark &> /dev/null \
            && ls ${QA_RESULTS}/data/${subPath}/${fBase[ix]}.clear &> /dev/null ; then
         isClear=t
       fi
    elif [ ${f%=*} = level -o ${f} != ${f/=/} -a ${f%=*} = tag ] ; then
       if [ ${f%=*} = level ] ; then
         # clear specified level
         f="^${f#*=}-"
       else
         # e.g. L1-${tag}: where tag=CF_12 would match CF_12, CF_12x etc.
         f="^[[:alnum:]]*-*${f#*=}.*: "
       fi

       local fl
       for fl in \
         $(ls ${QA_RESULTS}/data/${subPath}/qa_note_${fBase[ix]}* 2> /dev/null) \
         $( ls ${QA_RESULTS}/data/${subPath}/qa_lock_${fBase[ix]}* 2> /dev/null)
       do
        if grep -q $f $fl &> /dev/null ; then
          isClear=t
          break
        fi
       done
    elif [ ${f} != ${f/=/} -a ${f%=*} = var ] ; then
       # CLEAR=var=name
       if expr match ${fBase[ix]} "${f}" &> /dev/null ; then
         if ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* &> /dev/null
         then
           isClear=t
         fi
       fi
    else
       # CLEAR=varName
       f=${f%_} # this would allow for a variable 't_', which can be confused
                # without '_' with 't' meaning enabled.

       if expr match ${fBase[ix]} "${f}" &> /dev/null ; then
         if ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* &> /dev/null
         then
           isClear=t
         fi
       fi
    fi

    test ${isClear} = t && break
  done

  if [ ${isClear} = t ] ; then
    if [ "${isFL}" = t ] ; then
      # follow links
      fs=( $( \
           tryCom \
           ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* 2> /dev/null ) )

      for f in ${fs[*]} ; do
        if [ -h $f ] ; then
           deref_link target ${f}
           target=${target%/*}

           ts=( $( \
                tryCom \
                ls ${target}/*_${fBase[ix]}* 2> /dev/null  ) )

           for t in ${ts[*]} ; do
             if [ $isResume = t ] ; then
                tx=${t##*/}
                test "${tx:0:7}" != 'qa_lock' && continue
             fi

             if [ ${SHOW_CLEAR:-f} = t ] ; then
               std_out ttyOnly "SUB-PATH=${subPath}"
               std_out ttyOnly "\t${t}\tLINK\n"
             else
               # note: '\rm -f any' returns always 'true'
               if \
                  tryCom get_status \
                  \rm $t  ; then
                  isMessage=t
               fi
             fi
           done

           break
        fi
      done

      if [ $isMessage = t ]  ; then
        if [ $isResume = t ] ; then
          # only write a log message if targets of sym links were removed
          headerText="File:\t\tqa_${fBase[ix]}\n\
QA result path: ${target}\nResume: removed qa-break file by following links."
        else
          headerText="File:\t\tqa_${fBase[ix]}\n\
QA result path: ${target}\nRemoved QA results by following links."
        fi

        log_sessMessage "$headerText"
        isMessage=f
      fi
    fi

    # clearing section for regular files
    local isRm=f

    fs=( $( \
            tryCom get_status \
            ls ${QA_RESULTS}/data/${subPath}/*_${fBase[ix]}* 2> /dev/null ) )

    test -e ${QA_RESULTS}/data/${subPath}/core && fs[${#fs[*]}]=core

    for f in ${fs[*]} ; do
      if [ $isResume = t ] ; then
        tx=${f##*/}
        if [ "${tx:0:7}" = 'qa_lock' -o "${tx}" = 'core' ] ; then
          fs=($f)
          isRm=t
          break
        fi
      else
        # remove all

        isRm=t
        break
      fi
    done

    if [ ${isRm} = t ] ; then
       if [ ${SHOW_CLEAR:-f} = t ] ; then
         std_out ttyOnly "SUB-PATH=${subPath}"
         std_out ttyOnly "\t${fBase[ix]}\n"
       else
         # remove selected
         tryCom \
         \rm -f "${fs[*]}"
         isMessage=t
       fi
    fi

    # also delete table entries
    if [ $isClear = t ] ; then
       rmBlock $EXP_LOGDIR/$CURR_EXP_NAME.log ${fBase[ix]}
    fi

    if [ "$isMessage" != f ] ; then
      local note
      if [ ${isResume} != f ] ; then
         note="Resume: removed only qa-lock file."
      elif [ ${target} ] ; then
         note="Removed symbolic links."
      else
         note="Cleared QA results."
      fi

      # only write a log message if anything was removed
      headerText="File:\t\tqa_${fBase[ix]}\nPath: \t\t$PROJECT_DATA\n\
QA result path: $QA_RESULTS/data\nDRS tree:\t${subPath}\n${note}"

      log_sessMessage "$headerText"
    fi
  fi

  test ${isCLEAR_ONLY:-f} = t && return 0  # no qa
  test ${SHOW_CLEAR:-f}   = t && return 0  # no qa

  return 1
}

copyPreamble()
{
  local i zsTxt

  test ${isShow:-f} = t && return

  if [ -e $EXP_LOGDIR/${CURR_EXP_NAME}.log ] ; then
:
#    # a new qa svn revision number?
#    local rev_0 rev_1

#    # i) grep revision num save in
#    rev_0=( $(grep 'qa_svn_revision' $EXP_LOGDIR/${CURR_EXP_NAME}.log 2> /dev/null \
#         | awk -F: '{print $2}') )

#    if [ ! ${rev_0[0]} ] ; then
#      rev_0=0
#    else
#      rev_0=${rev_0[$(( ${#rev_0[*]} - 1 ))]}
#    fi

#    # ii) svn revision number saved in .conf
#     getRevNum rev_1

#    # is it newer
#    if [ ${rev_0[0]} -lt ${rev_1} ] ; then
#      if [ ${sTxt[0]} ] ; then
#        for(( i=0 ; i < ${#sTxt[*]} ; ++i )) ; do
#          zsTxt[i]="${sTxt[i]}"
#        done
#        unset sTxt
#      fi

#      sTxt[0]="3qa_svn_revision: ${rev_1}"
#      log
#    fi
  elif [ -f ${SESSION_LOGDIR}/session.prmbl ] ; then
       cp ${SESSION_LOGDIR}/session.prmbl $EXP_LOGDIR/${CURR_EXP_NAME}.log
#       local rev_1
#       getRevNum rev_1

#      if [ ${sTxt[0]} ] ; then
#        for(( i=0 ; i < ${#sTxt[*]} ; ++i )) ; do
#          zsTxt[i]="${sTxt[i]}"
#        done
#        unset sTxt
#      fi

#      sTxt[0]="3qa_svn_revision: ${rev_1}"
#      log
#    fi
 fi

# if [ ${zsTxt[0]} ] ; then
#   for(( i=0 ; i < ${#zsTxt[*]} ; ++i )) ; do
#     sTxt[i]="${zsTxt[i]}"
#   done
# fi

  return
}

displayStatusLine()
{
  local pbForStatus

  if [ "${progressAtomicNum}" -a ${progressTotalAtomicNum:-0} -gt 0  ] ; then
    pbForStatus=" (${progressAtomicNum}/${progressTotalAtomicNum})"

    local perc=$( echo "${progressAtomicNum} / ${progressTotalAtomicNum} * 100" | bc -l)
    # use if-construct, because this only works on AIX
    local is=$( echo "if ( ${perc} >= ${progressNext} ) 1" | bc -l )
    if [ ${is:-0} -eq 1 ] ; then
      # get next step
      is=$( echo "$perc / $progressStep" | bc -l )
      #discard decimal
      local i
      for(( i=0 ; i < ${#is} ; ++i )) ; do
         test ${is:i:1} = '.' && break
      done
      progressNext=$( echo "${is:0:i} * $progressStep +$progressStep" | bc -l)

      if [ ${PROGRESS_BAR} ] ; then
        eval echo "${progressAtomicNum} ${progressTotalAtomicNum}" ${progressFile}
      fi
    fi
  fi

  # no status line
  test ${SIMPLE_STATUS_LINE:-f} = f && return

  local num=$1
  shift
  local line="$*"

  local blank='          '
  local rpts=$(( repeats + 1 ))
  for(( l=0 ; l < rpts ; ++l )) ; do
    blank=${blank}'          '
  done
  std_out ttyOnly "\r${blank}\r"

  test ${num} -eq 0 && return

  std_out ttyOnly "${line} $pbForStatus"
  rp_num=$(( ${num} +15 ))
  repeats=$(( rp_num / 10 ))

  return
}

deref_link()
{
  # this is a robust version to dereference links, indepent on
  # the number of items given as output by 'ls -l'

  # $1: variable name to store the dereferenced file name
  # $2: the link

  local arr ipos
  arr=( $( \
           tryCom \
           ls -l $2 ) )

  for(( ipos=${#arr[*]}-1 ;ipos > -1 ; --ipos )) ; do
     test "${arr[ipos]}" = '->' && break
  done

  eval ${1}=${arr[$((ipos+1))]}

  return
}

executorRequestedExit()
{
  std_out flush "An executor instance requested EMERGENCY_STOP\nPlease, look for the reason in the session log-file."

  finally
  return
}

##//! Terminate current session

finally()
{
  test ${ONLY_SUMMARY:-f} = f && displayStatusLine 0

  wait_fnct  # give background processes a chance to finish;
             # locked processes are killed after a longer while

  if [ ${isTERM:-f} = t ] ; then
     # clear current results
     \rm -rf $PROC_POOL/*
  fi

  # release file with pid, if the session finished
  # rm filename with appended pid
  tryCom \
  \rm -f $QA_RESULTS/session_logs/PID/pid.$rootPID

  # directory containing files with PIDs of current qa-DKRZ runs.
  rmdir $SESSION_LOG/PID &> /dev/null # only if empty

  test ${FLOW_TRACE:-f} = t && tracePrint

  # Note: there could be 2 sub-dirs and files in PROC_POOL during operation.
  local f fs
  fs=( $( ls -d $PROC_POOL/* 2> /dev/null) )

  local count=0
  while [ ${#fs[*]} -gt 2 ] || ls -d $PROC_POOL/*/* 2> /dev/null ; do

    # the OS may have slow FS operations
    if [ $((count++)) -lt 5 ] ; then
      # final update of log-files
      checkClosedMessages

      sleep 0.1
      fs=( $( ls -d $PROC_POOL/* 2> /dev/null) )
      continue
    fi

    sendSubject=" PROC_POOL not cleared"
    sendText="qa-DKRZ.finally: ${PROC_POOL} was not cleared."

    log_sessMessage "$sendText"
    sendEMail
    break
  done

  std_out flush

  # rm PROC_POOL
  \rmdir ${PROC_POOL}/* 2> /dev/null
  \rmdir ${PROC_POOL}   2> /dev/null

  # rm pid-saving file
  \rm -f ${SESSION_LOGDIR}/pid.$rootPID

  if [ ${isShow:-f} = f ] ; then
    if [ ${isAnythingDone:-f} = t -a ${NO_SUMMARY:-f} = f ] ; then
      taskSum
    fi
  fi

  if [ ${#DEBUG_MANAGER} -gt 1 ] ; then
    set +x
    exec 2<&7 7<&-
    test ${dbgCycle} -eq 0 && \
      tryCom \
      mv ${DEBUG_MANAGER}.${dbgCycle} ${DEBUG_MANAGER}
  fi

  # remove empty paths from the results
  rmEmptyPaths

  if [ ${isTERM:-f} = t ] ; then
    kill -INT $$ 2&> /dev/null
  else
    exit ${lastStatus:-0}
  fi
}

##//! Show selected experiment names and exit.
getAllExps()
{
  local countLines
  local line
  local supPath
  local timeCounter=0

  declare -a line

  # save stdin
  exec 9<&0

  # connect file to input;
  # keep it open for reading while more paths may be appended.
  exec 0< $pathListFile

  while : ; do  # this loop resets when a race was lost

    while read -a line ; do
      test ${line[0]} = '---EOF---' && break 2

      subPath=${line[1]}
      PROJECT_DATA=${PROJECT_DATAV[${line[0]}]}

      # generate an experiment name; CURR_EXP_NAME gets a 'return value'
      if [ ${#EXP_PATH_INDEX[*]} -gt 0 ] ; then
        getExperimentName ${subPath}
      else
        local fs=( $( ls ${PROJECT_DATA}/${subPath}/*.nc 2> /dev/null) )
        getExperimentName ${fs[0]##*/}
      fi

      if [ ${SHOW_EXP:-f} = t ] ; then
        std_out ttyOnly "\r${blank}\r"
        std_out ttyOnly "EXP_NAME=${CURR_EXP_NAME}\n"
        std_out ttyOnly "PATH=${PROJECT_DATA}/${subPath}\n\n"
      fi
    done

    if [ ${SHOW_EXP:-f} = t ] ; then
      if [ ${timeCounter} -eq 50 ] ; then
        std_out ttyOnly "\r${blank}\r"
        timeCounter=0
      fi
      test ${SIMPLE_STATUS_LINE:-f} = f && std_out ttyOnly '.'
      timeCounter=$(( timeCounter + 1 ))
      sleep 1
    fi
  done

  # restore stdin and free #9
  exec 0<&9 9<&-
}

getCF_STD_NAME()
{
  local p
  p=${QA_SRC}/tables/projects/CF

  local name=cf-standard-name-table.xml

  # a short-cut. It is not necessary to poll pcmdi each call.
  if [ ${REFRESH_CF_STANDARD:-f} = t ] ; then
    wget --tries=3 -q -N --no-use-server-timestamps \
      --directory-prefix=$p \
      http://cf-pcmdi.llnl.gov/documents/cf-standard-names/standard-name-table/current/${name} \
      &> /dev/null
  fi

  return
}

getDateRange()
{

  # echo a date interval, or an instantaneous date none
  local f r

  test $# -eq 0 && return

  f=${1%.nc}

  # e.g. extracts both 186001-186612 and 186001-186612-clim
  r=$( expr match $f '.*_\([[:digit:]]*-[[:digit:]]*.*\)' )

  if [ ! ${r} ] ; then
    # no 'appendix allowed'
    r=$( expr match $f '.*_\([[:digit:]]*\)' )
  fi

  test ${r} && echo $r

  return
}

##//! Determine experiments to be processed during this session
##/*!
## The format of experiment names is ruled by the EXP_PATH_INDEX configuration option.
##*/

getExperimentName()
{
  # find and set CURR_EXP_NAME

  if [ ${EXP_NAME} ] ; then
    CURR_EXP_NAME=${EXP_NAME:-all-scope}
  elif [ ${EXP_FNAME_PATTERN} ] ; then
    getExperimentNameFromFile $1
  elif [ ${EXP_PATH_INDEX} ] ; then
    getExperimentNameFromPath $1
  fi

  local iex
  for(( iex=0 ; iex < ${#EXP_NAMES[*]} ; ++iex )) ; do
    if [ ${EXP_NAMES[iex]} = ${CURR_EXP_NAME} ] ; then
      return
    fi
  done

  # a new entry
  EXP_NAMES[${#EXP_NAMES[*]}]=${CURR_EXP_NAME}

  copyPreamble

  return
}

getExperimentNameFromFile()
{
  # see function initExperimentName()

  # EXP_NAME was defined in initExperimentName() and will never be
  # changed again

  # decompose the path
  local pc=${1%.nc}
  local pcs=( ${pc//${EXP_PAT_SEP}/ } )

  local i
  CURR_EXP_NAME=
  for(( i=EXP_PAT_BEG ; i < ${EXP_PAT_END:-${#pcs[*]}} ; ++i )) ; do
    if expr match ${pcs[i]} 'v[[:digit:]]' &> /dev/null
    then
      continue
    fi

    if expr match ${pcs[i]} '[[:digit:]]*-[[:digit:]]*' &> /dev/null
    then
      continue
    fi

    CURR_EXP_NAME=${CURR_EXP_NAME}${pcs[i]}_
  done
  CURR_EXP_NAME=${CURR_EXP_NAME%_}

  test ! ${CURR_EXP_NAME} && CURR_EXP_NAME=no-exp-name-found
  return
}

getExperimentNameFromPath()
{
  # extract the name of the experiment from subPath
  # see function initExperimentName()

  # EXP_NAME was defined in initExperimentName() and will never be
  # changed again

  # decompose the path
  local pcs
  pcs=${PROJECT_DATA}/$1
  pcs=( ${pcs//\// } )

  # check for path component 'output'
  test ! ${EXP_PATH_BASE} && EXP_PATH_BASE=${pcs[0]}

  local countEPB=0
  local c expPathIndex M N
  N=${#pcs[*]}

  for(( c=0 ; c < N ; ++c )) ; do
    if [ "${pcs[c]}" = ${EXP_PATH_BASE} ] ; then
      # check for an occurrence different than the left most
      if [ ${countEPB} -lt ${EXP_PATH_BASE_POS} ] ; then
        countEPB=$(( countEPB+1))
        continue
      fi

      local ix
      for(( ix=0 ; ix < ${#EXP_PATH_INDEX[*]} ; ++ix )) ; do
        expPathIndex[ix]=$(( c + ${EXP_PATH_INDEX[ix]} ))
      done
      break
    fi
  done

  test ${#expPathIndex[*]} -eq 0 && expPathIndex=( ${EXP_PATH_INDEX[*]} )

  # compose the name
  CURR_EXP_NAME=
  for c in ${expPathIndex[*]} ; do
    if [ $c -lt $N ] ; then
      # subtract the reversed positional index from array size
      CURR_EXP_NAME=${CURR_EXP_NAME}${pcs[c]}_
    else
      CURR_EXP_NAME=unknownExp
      break
    fi
  done
  CURR_EXP_NAME=${CURR_EXP_NAME%_}

  return
}

getFilenameBase()
{
  # an explicit file was selected
  if [ ${explFName} ] ; then
    fBase=${explFName}
    return
  fi

  local f i j k tmp
  unset fBase

  if [ ${QUERY_EMPTY_DIR:-f} = t ] ; then
    if find ${PROJECT_DATA}/${subPath} \
          -maxdepth 1 -type d -empty | grep -q .  ; then
      if [ ${YAML:-f} = f ] ; then
        gNV_log1 $1
      else
        y_impact=L2
        y_caption="empty directory"
        y_tag=M1
        y_status=1
        nextPath=${PROJECT_DATA}/${subPath}
        gNV_Ylog 'N/A'
      fi

      return
    fi
  fi

  if [ ${QUERY_NON_NC_FILE:-f} = t ] ; then
    fileNames=($(find ${PROJECT_DATA}/${subPath} -maxdepth 1 ! -type d -name "*"))
  else
    fileNames=($(find ${PROJECT_DATA}/${subPath} -maxdepth 1 -name "*.nc"))
  fi

  if [ ${IGNORE_BROKEN_LINKS:-f} = t ] ; then
    for(( j=${#fileNames[*]} - 1 ; j >= 0 ; --j )) ; do
      if [ -h ${fileNames[j]} -a ! -e ${fileNames[j]} ] ; then
        unset fileNames[$j]
      fi
    done
  fi

  fBase=( ${fileNames[*]#${PROJECT_DATA}/${subPath}/} )

  # find all available files: same root, but different time periods
  # is there any qa_*.nc ? Rather circuitous, but safe.
  # works also for names without appended date

  fBase=( ${fBase[*]%.nc} )

  # distinguish asd_range from asdf_range
  for(( i=0 ; i < ${#fBase[*]} ; ++i )) ; do
    tmp=$( getDateRange ${fBase[i]} )
    fBase[i]=${fBase[i]%_${tmp}}
  done

  # remove duplicates
  local sz
  sz=${#fBase[*]}
  for(( i=0 ; i < ${sz} ; ++i )) ; do
    test ${#fBase[i]} -eq 0 && continue

    for(( j=i+1 ; j < ${sz} ; ++j )) ; do
      test "${fBase[i]}" = "${fBase[j]}" && unset fBase[j]
    done
  done

  fBase=( ${fBase[*]} )

  return
}

##//! Get the name of a host ready for a start of the \a qaExecutor

##/*!
## All host must share the same file system. Names of hosts is
## supplied by the configuration option QA_EXEC_HOSTS. Maximum number of
## simultaneous qaExecutor instances is given by NUM_EXEC_THREADS.
##*/

getHost()
{
  # determination of a next host. The limits by
  # QA_EXEC_HOSTS and NUM_EXEC_THREADS are applied.

  # before that, however, check for closed message-files
  checkClosedMessages

  local loadShort load15min
  local currSec fileSec filePID xx

  local i j currHost currNum
  declare -a currNum

  if [ ${NIGHT_SHIFT:-f} = t ] ; then
    # only work at night time
    local dayTime
    dayTime=$(date +'%H')
    if [ $dayTime -lt 8 -o $dayTime -gt 18 ] ; then
      QA_EXEC_HOSTS=( ${save_QA_EXEC_HOSTS[*]} )
      NUM_EXEC_THREADS=( ${save_NUM_EXEC_THREADS[*]} )
    else
      QA_EXEC_HOSTS=( $HOSTNAME )
      NUM_EXEC_THREADS=( 1 )
    fi
  fi

  # preset
  for(( i=0 ; i < ${#QA_EXEC_HOSTS[*]} ; ++i )) ; do
    currNum[i]=0
  done

#  currSec=$( date +'%s' )  # works only for unix
  currSec=$( ${QA_BIN#*:}/unixTime.x )
  local f
  for f in $( ls -1 $PROC_POOL/*.lock 2> /dev/null ) ; do
    f=${f%.lock}

    # extract host name from the file
    currHost=${f%%:*}

    # check whether the process is old and if yes,
    # whether it is still alive

#    fileSec=$( fModTime.x $PROC_POOL/$f 2> /dev/null )
#    test ! ${fileSec} && continue  # lost the race

    # only for linux
# #   fileSec=$( ls -l --time-style=+'%s' $PROC_POOL/$line \
#              2> /dev/null |  awk '{print $6}' )


    # is file older than 2 hours?
#    if [ $(( currSec - fileSec - 7200 )) -gt 0 ] ; then
#      # is there any pending pid?
#      filePID=$( expr match $line '.*:.*:\(.*\)' )
#      if [ ${filePID} ] ; then
#         if [ "${currHost}" == "${HOSTNAME}" ] ; then
#           xx=$(ps hp $filePID)
#         else
#           xx=$(ssh $currHost ps hp $filePID)
#         fi

#         if [ ! ${xx} ] ; then
           #dead
#           \rm -f $PROC_POOL/$line   # lost the race
#           continue
#         fi
#      fi
#    fi

    # Determine the host names currently in use and
    # the number of corresponding instances of executors.
    for(( i=0 ; i < ${#QA_EXEC_HOSTS[*]} ; ++i )) ; do
      if [ "${currHost}" = "${QA_EXEC_HOSTS[i]}" ] ; then
        currNum[i]=$(( ${currNum[i]} + 1 ))
        continue 2
      fi
    done
  done

  # look for a free slot
  for(( j=0 ; j < ${#QA_EXEC_HOSTS[*]} ; ++j )) ; do
    if [ ${currNum[j]} -lt ${NUM_EXEC_THREADS[j]} ] ; then
      nextHost=${QA_EXEC_HOSTS[j]}

      # only select a host, if it is reachable
#      if ping -c 1 $nextHost &> /dev/null ; then
#      if callPing $nextHost ; then
        #only select host, if load is lower some limits
#        upTime=( $(ssh $nextHost uptime) )
#        i=$(( ${#upTime[*]} - 3 ))
#        loadShort=${upTime[i++]}
#        load15min=${upTime[++i]}

#        if [ $( echo "a=0;if(${loadShort%,} < 1.5)a=1;a" | bc -l) -eq 1 -a \
#          $( echo "a=0;if(${load15min} < 1.0)a=1;a" | bc -l) -eq 1 ] ; then

          return 0
#        fi
#      fi
    fi
  done

  # return, if maximum number of executors per host is reached
  return 1
}

##//! Get a list of sub-temporal files of a given variable.

##/*!
## Variable in the sense of CMIP5(CORDEX: name and MIP tabele/frequency.
## Linked files are treated according to the configuration option
## DEREFERENCE_SYM_LINKS. Locked variables are recognised.
##*/

getNextVariable()
{
  # $1 fBase

  # return 0, if a qa-check shall not be done(, mostly because it
  #           was already done previously), then idle.
  # return 1, if the file nextFile is going to be checked.

  # the path to the candidates of files to be checked
  nextPath=${PROJECT_DATA}/${subPath}

  # explict file is selected
  if [ ${explFName} ] ; then
    nextFile=${explFName}
    return 1
  fi

  local ix
  local text
  local status checksumTable

  local link_filenameBase=$1

  # get files with fBase (temporal information added)
  if [ ${QUERY_NON_NC_FILE:-f} = t ] ; then
    nV_fls=( $( find ${nextPath} -maxdepth 1 -type f -name "*" 2> /dev/null ) )
  else
    nV_fls=( $( find ${nextPath} -maxdepth 1 -name "${1}*.nc" 2> /dev/null ) )
  fi
  nV_fls=( ${nV_fls[*]#${nextPath}\/} )

  if [ ${#nV_fls[*]} -eq 0 ] ; then
    # empty dir was trapped before
    nextFile=  # ignore, try next
    return 0
  fi

  local num=${#nV_fls[*]}

  # check for broken symbolic links
  local f l is

  for(( l=${#nV_fls[*]} - 1 ; l >= 0 ; --l )) ; do
    f=$nextPath/${nV_fls[l]}
    if [ -h $f -a ! -e $f ] ; then
      if [ ${IGNORE_BROKEN_LINKS:-f} = t ] ; then
        continue
      else
        y_impact=L2
        y_caption='broken link'
        y_tag=M2
        initLog ${nV_fls[l]}

        is=t
      fi
    fi
  done
  if [ ${is:-f} = t ] ; then
    nextFile=  # ignore, try next
    return 0
  fi

  for(( l=0 ;  l < ${#nV_fls[*]} ; ++l )) ; do
    f=$nextPath/${nV_fls[l]}
    local num=${#nV_fls[*]}

    if [ ! -s $nextPath/${nV_fls[l]} ] ; then
      if [ ${QUERY_EMPTY_FILE:-f} = t ] ; then
        y_impact=L2
        y_caption='empty data file'
        y_tag=M3
        initLog ${nV_fls[l]}
        unset nV_fls[${l}]
      fi

      is=t
    elif ! expr match ${nV_fls[l]} "${1}.*\.nc" &> /dev/null ; then
      if [ ${QUERY_NON_NC_FILE:-f} = t ] ; then
        y_caption="invalid filename, found ${nV_fls[l]}"
        y_impact=L1
        y_tag=M6
        initLog ${nV_fls[l]}
        unset nV_fls[${l}]
      fi

      is=t
    fi
  done
  if [ ${is:-f} = t ] ; then
    nextFile=  # ignore, try next
    return 0
  fi

  nV_fls=( ${nV_fls[*]} )

  # check read permission on each file; this must be done prior the
  # call to syncFiles.x, because no permission would cause a
  # failed ambiguity check
  local f fp
  local is=f

  for(( f=0 ; f < ${#nV_fls[*]} ; ++f )) ; do
    if [ ! -r $nextPath/${nV_fls[f]} ] ; then
      y_impact=L2
      y_caption='no permission to read netCDF file'
      y_tag=M4
      initLog ${nV_fls[l]}

      finally
    fi
  done

  # there is no warning, when all files of a given variable
  # are broken links.
  if [ ${IGNORE_BROKEN_LINKS:-f} = t -a ! ${#nV_fls[*]} -eq 0 ] ; then
    nextFile=  # ignore, try next
    return 0
  fi

  # Note: if the first attempt of creating a qa-nc file
  # was interrupted by a system crash before closing it properly,
  # then the qa-nc file is corrupt. If a crash happened at any
  # further attempt to continue writing, then there will be a
  # back-up file available. Note: return value 0 (true) would happen
  # only, if there are more than one qa-files backup files.
  # The function shall clear such.
  if checkValidNcFile ${QA_RESULTS}/data/${subPath} $1 ; then
    nextFile=  # ignore, try next
    return 0
  fi

  # container for parameter passed to syncFiles.x
  syncOpts=$syncOptsInit

  # get name of file that has to be processed next (or none)
  local isMixingRefused=t
  if [ ${SYNC_FILE_AMBIGUITY_CHECK:-f} != f ] ; then
     local sfa
     local is
     for sfa in ${SYNC_FILE_AMBIGUITY_CHECK//,/ } ; do
       if [ ${sfa} = no_mod ] ; then
         is=f
       elif [ ${sfa} = mixed ] ; then
         syncOpts="${syncOpts} -m"
         isMixingRefused=f
       fi

       test ${is:-t} = t && syncOpts="${syncOpts} -M"
     done
  fi

  # Did checksums change?
  if [ ${CHECKSUM} ] ; then
    bind_checksum ${nV_fls[*]}
    status=$?

    # checksum has changed; remove qa results
    test $status -gt 1 && \rm ${QA_RESULTS}/data/${subPath}/qa_${1}.* 2> /dev/null

    if [ $status -eq 6 ] ; then
      # creation_date and/or tracking_id was kept
      nextFile=  # ignore, try next
      return 0
    fi
  fi

  qa_fl=$( ls ${QA_RESULTS}/data/${subPath}/qa_${1}.nc 2> /dev/null)

  # apply rules, clearings, and test for qa_note files
  if \
#trace \
    testLocks $1 $qa_fl ; then
      nextFile=  # ignore, try next
      return 0
  fi

  # sync with qa_file if available
  #exception: only scan for the tracking id
  if [ "${qa_fl}" -a ${TRACKING_ID_ONLY:-f} = f ] ; then
    syncOpts="${syncOpts} -p ${qa_fl}"
  fi

  # any time limit specified?
  local tl
  test ${TIME_LIMIT} && syncOpts="${syncOpts} -l ${TIME_LIMIT}"

  unset nextFile

  if [ ${isMixingRefused} = t -a ${IGNORE_TEMP_FILES:-f} = t ] ; then
    local tf tff tfs
    declare -a tfs
    declare -a tff

    for tf in ${nV_fls[*]} ; do
      # exclude fixed variables from ignoring
      tff=${tf#*_}
      tff=${tff%%_*}

      if [ "${tff}" != fx ] ; then
        tff=
        tff=$( getDateRange $tf )
        test ! ${tff} && continue
      fi

      tfs[${#tfs[*]}]=$tf
    done

    nV_fls=( ${tfs[*]} )

    if [ ${#nV_fls[*]} -eq 0 ] ; then
      nextFile=  # ignore, try next
      return 0
    fi
  fi

  nextFile="$(echo ${nV_fls[*]} | ${QA_BIN#*:}/syncFiles.x \
     $syncOpts -P ${nextPath} )"

  status=$?

  test ${SHOW_SYNC:-f} = t && \
       std_out flush "${nextFile[*]/%/\\n}"

  local nFsSz=${#nextFile[*]}

  # up-to-date
  if [ ${status} -eq 1 ] ; then
#    if [ ${PROGRESS_BAR} ] ; then
      # get number of data files for progress estimation
      # note: all files no matter whether processed or locked
      local num=${#nV_fls[*]}
#    fi

    nextFile=
    return 0
  fi

  if [ $status -eq 3 ] ; then
#    if [ ${PROGRESS_BAR} ] ; then
      local num=${#nV_fls[*]}
#    fi

    isAnythingDone=t

    y_impact=L2
    y_caption='syncFiles.cpp with unspecific failure'
    y_tag=M5
    y_meta_data=OMIT
    y_time_values=FAIL
    y_status=${status}

    local k
    for(( k=0 ; k < ${#nextFile[*]} ; ++k )) ; do
      y_text[${k}]="${nextFile[k]}"
    done

    initLog $1

    nextFile=  # ignore, try next
    return 0
  fi

  # a fixed variable?
  if [ $status -eq 4 ] ; then
    # already processed?
    if [ ${qa_fl[0]} ] ; then
#      if [ ${PROGRESS_BAR} ] ; then
        # get number of data files for progress estimation
        # note: all files no matter whether processed or locked
        local num=${#nV_fls[*]}
#      fi

      nextFile=
      return 0
    fi
  fi

  # SYNC_FILE_AMBIGUITY_CHECK failed?
  if [ $status -gt 10 ] ; then
#    if [ ${PROGRESS_BAR} ] ; then
      local num=${#nV_fls[*]}
#    fi

    isAnythingDone=t

    # issue annotation
    y_impact=L2
    y_caption='syncFiles.cpp: sub-temporal file sequence ambiguities.'
    y_tag=M6
    y_meta_data=OMIT
    y_time_values=FAIL
    y_status=${status}

    local yCount=0
    local l;
    for(( k=0 ; k < ${#nextFile[*]} ; ++k )) ; do
      for(( l=0 ; l < ${#nextFile[k]} ; ++l )) ; do
        if [ "${nextFile[k]:l:2}" = "\n" ] ; then
           yCount=$(( yCount +1 ))
           break
        else
          y_text[yCount]="${y_text[yCount]}${nextFile[k]:l:1}"
        fi
      done
    done

    initLog $1

    nextFile= # ignore, try next
    return 0
  fi

  # expand \n
  nextFile=( ${nextFile[*]//\\n/ } )

  # nextFile is the first sub-temporal file, i.e. candidate for
  # a parent check.
  IS_FIRST_SUB_TEMP=f
  test ! ${qa_fl} && IS_FIRST_SUB_TEMP=t

  if [ ${DEREFERENCE_SYM_LINKS:-f} = f -a \
        -h ${PROJECT_DATA}/${subPath}/$nextFile ] ; then
    # make links for QA results, where links are in the DRS tree
    # (not for links to the outside of the DRS tree).
    testFileLink $1
    nextFile= # ignore, try next
    unset nV_fls
    return 0
  fi

  return 1
}

##//! Get sub-path to a variable scheduled next.

getNextSubPath()
{
  # subPaths from a temporary file redirected to stdin.
  local ix line

  # init progress estimation
#  if [ ${PROGRESS_BAR} ] ; then
    if [ ${progressTotalAtomicNum:-0} -eq 0 ] ; then
      if [ "$(tail -n 1 ${pathListFile})" = '---EOF---' ] ; then
        progressTotalAtomicNum=$(wc -l ${pathListFile} | awk '{print $1}')
        progressTotalAtomicNum=$(( progressTotalAtomicNum -1 ))
      fi
    fi
#  fi

  # pathListFile was connected to stdin in check()
  while : ; do  # for trapping the end

  while read -a line ; do
    # return 1: fade out operation
    if [ ${line[0]} = '---EOF---' ] ; then
      unset fBase
      fBase=''
      subPath=''
      explFName=''
      return
    fi

    progressAtomicNum=$(( ${progressAtomicNum} + 1 ))

    subPath=${line[1]}
    explFName=${line[2]}  # available only for a single file selection
    PROJECT_DATA=${PROJECT_DATAV[${line[0]}]}

    # if read returned true, although there was currently no more entry
    test "${prevLine}" = "${subPath}" && break
    prevLine=${subPath}

    # find the root of all files, stripping of date-periods;
    # puts names to fBase
#trace \
    getFilenameBase

    if [ ${#fBase[*]} -gt 0 ] ; then
      # found unlocked variable (constraint: SHOW_CLEAR=f)
      mkdir -p ${QA_RESULTS}/data/${subPath}

      if [ ${waitCounter} -gt 0 ] ; then
        displayStatusLine 51 ''
        waitCounter=0
      fi

      return
    fi
  done

  # for EOF case
  # a getSelectedPath process is still running; kill it
  if ps -p ${getPathPID:-0} -o pid= &> /dev/null  ; then
    # the search for paths did not finish, yet.
    test ${waitCounter} -eq 0 && displayStatusLine 51 "."
    waitCounter=$(( waitCounter + 1 ))

    test ${waitCounter} -eq 50 && waitCounter=0

    std_out ttyOnly '.'
    sleep 1
  fi

  done

  return
}

##//! Get paths to all variables scheduled for processing.

##/*!
## The function runs in the back-ground and writes all paths found
## to a temporary file. SELECTion and LOCK assigned in the configuration
## are applied.
##*/

getPaths()
{
  test ! ${DEBUG_MANAGER} && voidX
  # if set -x enabled, then disable for this function

  # Get all paths to sub-dirs that contain netCDF file(s)
  # and list these in a temp file in the directory Project_table.

  test ${SHOW_PATH_SEARCH:-f} = t && set -x

  set -f

  # filename
  pathListFile=${SESSION_LOGDIR}/path-list.txt

  PROJECT_DATAV=( ${PROJECT_DATAV[*]//,/ } )

  # very special: no SELECT at all
  if [ ${#SELECT_PATH_LIST[*]} -eq 0 \
        -a ${#SELECT_VAR_LIST[*]} -eq 0 ] ; then
    local i
    for(( i=0 ; i < ${#PROJECT_DATAV[*]} ; ++i )) ; do

      if [ -f ${PROJECT_DATAV[i]} ] ; then
        # it is a file !!!
        SELECT_VAR_LIST[${#SELECT_VAR_LIST[*]}]=${PROJECT_DATAV[i]##*/}
        PROJECT_DATAV[i]=${PROJECT_DATAV[i]%/*}
        SELECT_PATH_LIST[${#SELECT_PATH_LIST[*]}]=${PROJECT_DATAV[i]##*/}
        PROJECT_DATAV[i]=${PROJECT_DATAV[i]%/*}
      else
        # a directory or something with RegExpr
        splitAtRegExp ${PROJECT_DATAV[i]}

        if [ ! ${splitRE_1} ] ; then
          SELECT_PATH_LIST[${#SELECT_PATH_LIST[*]}]='.*'
        else
          SELECT_PATH_LIST[${#SELECT_PATH_LIST[*]}]=${splitRE_1}
          PROJECT_DATAV[i]=${splitRE_0}
        fi

        SELECT_VAR_LIST[${#SELECT_VAR_LIST[*]}]='.*'
      fi
    done
  fi

  # very special: a SELECT of a full path
  # take into account selections from outside of PROJECT_PATH,
  # i.e. such with a leading /
  for(( l=0 ;  l < ${#SELECT_PATH_LIST[*]} ; ++l )) ; do
    item=${SELECT_PATH_LIST[l]}

    for(( k=0 ; k < ${#PROJECT_DATAV[*]} ; ++k )) do
      # split selected path into components
      if [ "${item:0:1}" = '/' ] ; then
        # though absolute, it is within P_D
        test ${item} != ${item#${PROJECT_DATAV[k]}}  && continue 2
      else
        continue 2
      fi
    done

    # A selection with absolute path, which doesn't fit PROJECT_DATA.
    if [ -f $item ] ; then
      # it is a file !!!
      SELECT_VAR_LIST[l]=${item##*/}
      item=${item%/*}
      SELECT_PATH_LIST[l]=${item##*/}
      PROJECT_DATAV[${#PROJECT_DATAV[*]}]="${item%/*}"
    elif [ -d $item ] ; then
      # a directory with or without var-selection
      SELECT_PATH_LIST[${l}]=${item##*/}
      PROJECT_DATAV[${#PROJECT_DATAV[*]}]=${item%/*}
    else #if [ ${SELECT_VAR_LIST[${l}]} != '.*' ] ; then
      # a directory with var-selection
      splitAtRegExp ${item}

      if [ ! ${splitRE_1} ] ; then
        SELECT_PATH_LIST[${l}]=${splitRE_0##*/}
        PROJECT_DATAV[${#PROJECT_DATAV[*]}]=${splitRE_0%/*}
      else
        SELECT_PATH_LIST[${l}]=${splitRE_1}
        PROJECT_DATAV[${#PROJECT_DATAV[*]}]=${splitRE_0}
      fi
    fi
  done

  test ${ONLY_SUMMARY} && REUSE_PATH_LIST=t

  # only those paths that are selected and contain netCDF files
  if [ ${REUSE_PATH_LIST:-f} = f \
       -o ! -f ${SESSION_LOGDIR}/path-list.txt ] \
       || ! grep -q -- '---EOF---' ${SESSION_LOGDIR}/path-list.txt ; then
    \rm -f "${pathListFile}"

    if is_TPUT ; then
      echo "getPaths ... " > $TTY
    fi

    getSelectedPaths ${PROJECT_DATAV[*]} &
    getPathPID=$!
  fi

  set +f

  if [ ${SHOW_PATH_SEARCH:-f} = t ] ; then
    set +x
    wait
    exit
  fi

  # Only pass the loop when the file is already partially filled.
  # Then, it is garantueed that there will be an EOF mark.
  while : ; do
    test ! -e ${pathListFile} && continue

    while [ ! -s ${pathListFile} ] ; do
      sleep 1
    done

    break
  done


  if [ "$( head -n 1 $pathListFile)" = '---EOF---' ] ; then
    if [ ${#PROJECT_DATAV[*]} -eq 1 ] ; then
      sTxt[0]="3data_path: ${PROJECT_DATAV}"
    else
      local tt="${PROJECT_DATAV[*]}"
      sTxt[0]="3data_path: [${tt// /, }]"
    fi

    sTxt[1]="3text: 1"
    sTxt[2]="3 - no valid sub-path found in data_path"

    std_out flush "${sTxt[0]:1}\n${sTxt[2]:4}"

    sendSubject="qa-DKRZ: SELECT/LOCK conflict"

    sendEMail
    lastStatus=1  # exit status of this script
    exit
  fi

  test ! ${DEBUG_MANAGER} && voidX # roll back enabled set -x
}

getProjectTableName()
{
  # extract the name of the project table from subPath
  # see function initExperimentName()

  PROJECT_TABLE=$PRJCT_BASENAME

  # no automatic construction
  test ! ${PT_PATH_INDEX} && return

  # decompose the path
  local pcs
  pcs=$PROJECT_DATA/$1
  pcs=( ${pcs//\// } )

  # if the last item on the right side is a kind of version, then skip
  local c ptPathIndex
  ptPathIndex=( ${PT_PATH_INDEX[*]} )

  local sz=$((${#pcs[*]}-1))

  if expr match ${pcs[sz]} 'v[[:digit:]]' &> /dev/null
  then
    # adjust indexes, because there is a trailing version_path_item
    for(( c=0 ; c < ${#ptPathIndex[*]} ; ++c )) ; do
      ptPathIndex[${c}]=$(( ${ptPathIndex[c]} +1 ))
    done
  fi

  # compose the name
  local N=${#pcs[*]}

  for c in ${ptPathIndex[*]} ; do
    if [ $c -lt $N ] ; then
      # subtract the reversed positional index from array size
      PROJECT_TABLE=${PROJECT_TABLE}${pcs[$(( N - c ))]}_
    else
      PROJECT_TABLE=unknownExp
      break
    fi
  done
  PROJECT_TABLE=${PROJECT_TABLE%_}.csv

  return
}

getRevNum()
{
  # get the number saved in QA_SRC/.conf as revision=num
  local rev revs
  revs=( $( grep 'revision=' ${QA_SRC}/.conf 2> /dev/null \
       | awk -F= '{print $2}' ) )

  if [ ! ${revs[0]} ] ; then
    rev=-1
  elif [ ${#revs[*]} -eq 1 ] ; then
    rev=${revs[0]}
  else
    // several numbers are available by mistake; get the highest one
    rev=0
    local r
    for r in ${revs[*]} ; do
      test $r -gt $rev && rev=$r
    done
  fi

  eval $1=${rev}
  return
}

getSelectedPaths()
{
  # descent recursively into dirs and write all sub-paths,
  # containing at least one netCDF file,
  # into a file.
  test ${SHOW_PATH_SEARCH:-f} = f && set +x

  local currDirs projectDataIndex
  declare -a currDirs projectDataIndex

  local e i j k l s

  set +f

  if [ ${isStart:-t} = t ] ; then
    isStart=f

    # first depth
    if [ ${#SELECT_PATH_LIST[*]} -eq 0 ] ; then
      SELECT_PATH_LIST=( '.*' )
      SELECT_VAR_LIST=( '.*' )
    fi

    splCount=${#SELECT_PATH_LIST[*]}
    lplCount=${#LOCK_PATH_LIST[*]}

    for(( k=0 ; k < lplCount ; ++k )) ; do
      LOCK_PATH_LIST[${k}]=".*${LOCK_PATH_LIST[k]}"
    done

    local item items sub0 sub1 projectDataPath
    declare -a items projectDataPath

    projectDataPath=( $* ) # actually PROJECT_DATA paths
    recurrCount=0

    for(( k=0 ; k < ${#projectDataPath[*]} ; ++k )) do
      isPDP_only=t

      for(( l=0 ;  l < ${splCount} ; ++l )) ; do
        # split selected path into components
        item=${SELECT_PATH_LIST[l]}
        item=${item#${projectDataPath[k]}/}
        items=( ${item//\// } )
        test "${item:0:1}" = '/' && break

        sub0=

        # look for an alpha-numeric sub-path leading a selected path
        for(( i=0 ; i < ${#items[*]} ; ++i )) ; do
          if expr match ${items[i]} "[[:alnum:]_-]\{${#items[i]}\}" &> /dev/null ; then
            # only accept valid paths
            sub1=${sub0}/"${items[i]}"
            test ! -e ${projectDataPath[k]}$sub1 && break

            sub0=$sub1
          else
            break
          fi
        done

        if [ ${sub0} ] ; then
          isPDP_only=f
          currDirs[${#currDirs[*]}]=${projectDataPath[k]}$sub0
          basePaths[${#basePaths[*]}]=${projectDataPath[k]}
          projectDataIndex[${#projectDataIndex[*]}]=$k
        fi
      done

      if [ ${isPDP_only} = t ] ; then
        currDirs[${#currDirs[*]}]=${projectDataPath[k]}$sub0
        basePaths[${#basePaths[*]}]=${projectDataPath[k]}
        projectDataIndex[${#projectDataIndex[*]}]=$k
      fi
    done
  else
    # deeper recurrence level
    currDirs=( $* )
    recurrCount=$(( recurrCount + 1 ))
  fi

  local entries

  for(( i=0 ; i < ${#currDirs[*]} ; ++i )) ; do
    # Multiple currDirs and basePaths are only possible in the zero-th recursion level.
    # In higher levels, basePath inherits the value from the parent, when getSelected
    # was called there.
    currDir=${currDirs[i]}

    if [ ${recurrCount} -eq 0 ] ; then
      # will be inhereted in deeper recursion levels
      prjDataIndex=${projectDataIndex[i]}
      basePath=${projectDataPath[prjDataIndex]}
    fi

    entries=( $(ls -d $currDir/* 2> /dev/null) )

    if [ ${HIDDEN_DIRECTORIES:-f} = t ] ; then
      local hidden
      hidden=( $(ls -ad $currDir/.* 2> /dev/null) )
      if [ ${#hidden[*]} -gt 2 ] ; then
        # rm . and ..
        for(( j=${#hidden[*]}-1 ; j > -1 ; --j )) ; do
          test ${hidden[j]##*/} = '.' -o ${hidden[j]##*/} = '..' \
              && unset hidden[${j}]
        done

        entries=( ${entries[*]} ${hidden[*]} )
      fi
    fi

    # check for a variable selection (which is also a directory)
    for(( s=0 ; $s < $splCount ; ++s )) ; do
      # case that a filename is appended
      if [ -f "${currDir}/${SELECT_VAR_LIST[s]##*/}" ] ; then
        # write sub-path with a leading  slash
        echo -n "${prjDataIndex} ${currDir#${basePath}/}" >> $pathListFile
        echo    " ${SELECT_VAR_LIST[s]##*/} " >> $pathListFile
        break
      fi

      if expr match "$currDir" "${basePath}/${SELECT_PATH_LIST[s]}" &> /dev/null
      then

        for entry in ${entries[*]} ; do
          # check only netCDF files
          test -d $entry && continue

          if [ ${QUERY_ONLY_NC:-f} = t ] ; then
             test ${entry} = ${entry%.nc} && continue
          elif [ ${QUERY_ALIEN_FILE:-f} = f ] ; then
            test -d $entry -o ".${entry##*.}" != ".nc" && continue
          fi

          e=${entry##*/}

          if expr match "$e" "${SELECT_VAR_LIST[s]}" &> /dev/null
          then

            for(( l=0;  $l < $lplCount ; ++l )) ; do
              if expr match ${currDir} "${LOCK_PATH_LIST[l]}" &> /dev/null
              then
                if expr match ${e} "${LOCK_VAR_LIST[l]}" &> /dev/null
                then
                  # this dir and its descendents are locked. But,
                  # occurrence of multiple variables is possible, thus
                  # no return; just ignore this one and continue.
                  break 2
                fi
              fi
            done

            # found a valid selection; is it unique?
            if ! grep -q ${currDir#${basePath}} $pathListFile \
                  &> /dev/null ; then
              # write sub-path with a leading  slash
              echo "${prjDataIndex} ${currDir#${basePath}/}" >> $pathListFile
            fi

            # this break allows nc-files not only at the end-branches of
            # a directory structure, but also embedded.
            break 2  # only the path is needed
          fi
        done

      fi
    done

    # descend deeper
    for e in ${entries[*]} ; do
      if [ -d $e ] ; then

        # cancel entirely LOCKed directories
        for(( l=0;  $l < $lplCount ; ++l )) ; do
          if expr match ${e} "${LOCK_PATH_LIST[l]}" &> /dev/null
          then
             test "${LOCK_VAR_LIST[l]}" = '.*' && continue 2
          fi
        done

        getSelectedPaths $e
        recurrCount=$(( recurrCount - 1 ))
      fi
    done
  done

  # append End Of File mark
  test ${recurrCount} -eq 0 && echo '---EOF---' >> $pathListFile

  return
}

has()
{
  local c i j t

  if [ ${1:0:7} = '--char=' ] ; then
    if [ ${#1} -eq 7 ] ; then
      c=' '
    else
      c=${1#*=}
      if [ ${#c} -gt 1 ] ; then
        t=${c}
        unset c
        for(( i=0 ; i < ${#t} ; ++i )) ; do
          c[${#c[*]}]="${t:i:1}"
        done
      fi
    fi

    shift 1
  else
    c=','
  fi

  t="$*"

  for(( j=0 ; j < ${#c[*]} ; ++j )) ; do
    for(( i=0 ; i < ${#t} ; ++i )) ; do
     test "${t:i:1}" = "${c[j]}" && return 0
   done
  done

  return 1
}


##//! Initialisation of a session

##/*!
## Starts script \a qaConfiguration.
##*/

init()
{
  # setting defaults, parsing of the configuration file and
  # command-line is left to the
  # qaConfiguration, which returns key-word assignments and lists.

  # look if argc contains a tty statement
  local is

  for(( i=1 ; i < $# ; ++i )) ; do
    test ${!i} = -x && set -x && continue
    if [ ${!i} = -T ] ; then
       i=$(( i + 1 ))
       TTY=${!i}
    fi
  done

  local T
  if [ -c "$TTY" ] ; then
    T=( -T ${TTY} )
  fi

  # some defaults
  CLOSED_TTY=f
  NO_STATUS=f
  isTPUT=f

  # configuration
  callQaConfig ${T[*]} $*

  if is_TTY  ; then
    if [ $NO_STATUS = f ] ; then
     if [ ${SIMPLE_STATUS_LINE:-f} = t ] ; then
       isTPUT=t
        if ! which tput &> /dev/null ; then
          isTPUT=f
        fi
      fi
    fi
  fi

  if [ ${QA_EXAMPLE:-f} = t ] ; then
    # run example for CORDEX
    runExample
    exit
  fi

  test ! ${PROJECT} && PROJECT=NONE
  test ! ${PROJECT_AS} && PROJECT_AS=${PROJECT}

  # package update requested and required?
  if [ !${NO_GIT} ] \
          && ! ${QA_SRC}/install ${INSTALL_ARGS//,/ } ${PROJECT_AS} ; then
    # could not make the executable for the given project
    std_out flush "could not make: install ${PROJECT_AS}"
    exit 1
  fi

  # expand comma-sep-list to arrays
  EMAIL_SUMMARY=( ${EMAIL_SUMMARY//,/ } )
  EMAIL_TO=( ${EMAIL_TO//,/ } )
  QA_BIN=( ${QA_BIN//,/ } )
  QA_EXEC_HOSTS=( ${QA_EXEC_HOSTS//,/ } )
  NUM_EXEC_THREADS=( ${NUM_EXEC_THREADS//,/ } )

  # set defaults
  test ${ZOMBIE_LIMIT:-f} = f && ZOMBIE_LIMIT=3600

  # shut down any console messaging
  if [ ${QUIET:-f} = t ] ; then
    CLOSED_TTY=t
  fi

  if [ ${CHECKSUM:-f} = f ] ; then
    test "${CS_STAND_ALONE}" -o "${CS_DIR}" && CHECKSUM=t
  fi

  # no status for SHOW_CALL
  test ${SHOW_CALL:-f} = t && NO_STATUS=t
  test ${SIMPLE_STATUS_LINE:-f} = f && NO_STATUS=t

  # parse REATTEMPT_LIMIT and SLEEP_TIME
  intTryComRepeat

  # Are the executables in QA_BIN applicable?
  if ! ${QA_BIN#*:}/unixTime.x &> /dev/null ; then
    sTxt[0]="3text: 1"
    sTxt[1]="3 - no executables in ${QA_BIN}"

    std_out flush "${sTxt[0]:1}\n${sTxt[1]:4}"
    sendEMail

    if is_TPUT ; then
      tput cuu 1 > $TTY
      tput dl 1 > $TTY
    fi

    finally
  fi

  # convert special characters to escaped ones.
  local i

#  set -f
  # read ~/.qa-dkrz/conf-.txt for the current revision of tha package
  . $QA_SRC/scripts/updateConfigFile.txt QA_REVISION

  maxNumExecThreads=0
  local nET
  for nET in ${NUM_EXEC_THREADS[*]} ; do
    maxNumExecThreads=$(( maxNumExecThreads + nET ))
  done

  initProjectTableName

  initTables

  # save the configuration and init the session logfile
  logConfiguration $*

  local pidFile=${SESSION_LOGDIR}/pid.$rootPID

  if [ ${SHOW_CALL:-f} = f ] ; then
    # file pid.$$ contains three lines:
    # 1) path to dir where this process was started.
    # 2) the command line arguments to start plus PID of this.
    # 3) the current session path and logfile name
    tryCom \
    echo "$(pwd)"             > $pidFile
    tryCom \
    echo -n "$*"             >> $pidFile
    tryCom \
    echo " --fpid $rootPID"  >> $pidFile
    tryCom \
    echo "$SESSION_LOGDIR/session.log" >> $pidFile
  fi

  maxSleep=1  # maximum duration of incremented sleep periods

  # temporary directory for exchanges between manager and executor
  PROC_POOL=$SESSION_LOGDIR/ProcPool

  if ! mkdir -p ${PROC_POOL} &> /dev/null ; then
    sTxt[0]= "3text: 1"
    sTxt[1]= "3 - could not mkdir PROC_POOL=${PROC_POOL}"

    std_out flush "${sTxt[2]:4}"

    sendSubject="could not mkdir PROC_POOL"
    sendEMail

    lastStatus=2  # exit status of this script
    exit
  fi

  # sub-dirs for temporary session- and experiment log-files
  tryCom \
  mkdir -p ${PROC_POOL}/session &> /dev/null
  tryCom \
  mkdir -p ${PROC_POOL}/experiments &> /dev/null

  # initialisation of the indexes of DRS tokens for the experiment name
  initExperimentName

  if [ ${SUMMARY_ONLY} ] ; then
    ONLY_SUMMARY="${SUMMARY_ONLY}"
  elif [ ${SUMMARY} ] ; then
    ONLY_SUMMARY="${SUMMARY}"
  fi
  if [ ${ONLY_SUMMARY:-f} != f -a ${isShow:-f} = f ] ; then
     if [ ${ONLY_SUMMARY} = t ] ; then
       getPaths
       getAllExps
     else
       if [ ${ONLY_SUMMARY} = all ] ; then
        EXP_NAMES=( $(ls -d ${QA_RESULTS}/check_logs/*.log) )
        EXP_NAMES=( ${EXP_NAMES[*]##*/} )
       else
        EXP_NAMES=( ${ONLY_SUMMARY//,/ } )
       fi

       local i
       for(( i=0 ; i < ${#EXP_NAMES[*]} ; ++i )) ; do
         if [ ${EXP_NAMES[i]} != ${EXP_NAMES[i]%.log} ] ; then
           EXP_NAMES[${i}]=${EXP_NAMES[i]%.log}
         fi
       done
     fi

     taskSum
     exit
  fi

  # identifier for semaphore file (incremented)
  EX_ID=$rootPID  # just a starting point

  # get all selected, non-locked paths
  getPaths

  # reassure that TTY is still valid
  if [ ${ONLY_SUMMARY:-f} = f ] && is_TPUT ; then
    tput cuu 1 > $TTY
    tput dl 1 > $TTY
  fi

  syncOptsInit='--only-marked'

  # progress bar
#  if [ ${PROGRESS_BAR:-f} = t ] ; then
    # write to stdout
  if [ ${PROGRESS_BAR} ] ; then
    # (over)write to a file and set percentage stepping
    local pbs=( ${PROGRESS_BAR//,/ } )
    local pb
    for pb in ${pbs[*]} ; do
      if expr match ${pb} '.*[[:alpha:]]' &> /dev/null ; then
        progressFile=" >> ${pb}"
      fi
      if ! expr match ${pb} '.*[[:alpha:]]' &> /dev/null ; then
        progressStep=$pb
      fi
    done

    test ! ${progressStep} && progressStep=1  # %
    progressNext=$progressStep
  else
    progressStep=1  # %
    progressNext=1
  fi

  test ${USE_STRICT:-f} = t -a ! "${CHECKSUM}" && CHECKSUM=t

  # counter for NEXT
  fileCount=0

}

initExperimentName()
{
  # provided EXP_NAME has preference
  if [ ${EXP_NAME} ] ; then
    unset EXP_FNAME_PATTERN
    unset EXP_PATH_INDEX

  elif [ ${EXP_FNAME_PATTERN} ] ; then
    local items=( ${EXP_FNAME_PATTERN//\// } )
    local item
    EXP_PAT_BEG=0
    EXP_PAT_SEP=_

    for item in ${items[*]} ; do
      if [ ${item:0:1} = b ] ; then
        EXP_PAT_BEG=${item:1}
      elif [ ${item:0:1} = e ] ; then
        EXP_PAT_END=${item:1}
      elif [ ${item:0:1} = s ] ; then
        EXP_PAT_SEP=${item:1}
      fi
    done

    unset EXP_PATH_INDEX

  elif [ ${EXP_PATH_INDEX} ] ; then
    # extract the name of the experiment from subPath
    # Explanation: look for EXP_PATH_INDEX in a configuration file

    # we need a real array
    EXP_PATH_INDEX=( ${EXP_PATH_INDEX//,/ } )
    EXP_PATH_INDEX_MAX=100  # exceeds any number of path components

    # note: the highest number points to the most left-side
    # path component

    EXP_PATH_INDEX_MAX=0

    local t
    for t in ${EXP_PATH_INDEX[*]} ; do
      test ${t} -gt ${EXP_PATH_INDEX_MAX} && EXP_PATH_INDEX_MAX=${t}
    done

    # for multiple occurrences
    EXP_PATH_BASE_POS=0
    if [ "${EXP_PATH_BASE/:/}" != "${EXP_PATH_BASE}" ] ; then
      EXP_PATH_BASE_POS=${EXP_PATH_BASE##*:}
    fi
  else
    EXP_NAME='all-scope'
  fi

  return
}

##//! Init annotation logging

initLog()
{
  sTxt[$((ix++))]="3file: $1"
  sTxt[$((ix++))]="3data_path: ${nextPath}"
  sTxt[$((ix++))]="3result_path: ${QA_DATADIR}/${subPath}"
  sTxt[$((ix++))]="3check:"
  sTxt[$((ix++))]="4meta_data: ${y_meta_data:-FAIL}"
  sTxt[$((ix++))]="4time_values: ${y_time_values:-OMIT}"
  sTxt[$((ix++))]="4data: ${y_data:-OMIT}"
  sTxt[$((ix++))]="3events:"
  sTxt[$((ix++))]="3 - event:"
  sTxt[$((ix++))]="7caption: \'${y_caption}\'"
  sTxt[$((ix++))]="7impact: ${y_impact}"
  sTxt[$((ix++))]="7tag: \'${y_tag}\'"

  y_meta_data=
  y_time_values=
  y_data=

  local i
  if [ "${y_text[0]}" ] ; then
    sTxt[$((ix++))]="7text:"
    for(( i=0 ; i < ${#y_text[*]} ; ++i )) do
      sTxt[$((ix++))]='7 - '"${y_text[i]}"
    done
    unset y_text
  fi

  sTxt[$((ix++))]="3status: ${y_status:-0}"
  y_status=

  local out=${QA_RESULTS}/data/${subPath}/qa_lock_${1}.txt
  echo "Path: ${nextPath}"                  > $out
  echo "File: ${1}"                        >> $out
  echo "${impact}-${tag}: ${y_caption}" >> $out

  log

  sendSubject="Annotation: ${y_caption}"
  sendEMail
}

##//! Determination of various tables for the QA.

##/*!
## At the very first start, the script puts user-provided tables
## into QA_RESULTS/tables which are used during the further session.
##*/

initProjectTableName()
{
  if [ ${PROJECT_TABLE_PREFIX} ] ; then
    local sz=${#PROJECT_TABLE_PREFIX}
    test ${PROJECT_TABLE_PREFIX:$((sz-1)):1} != '_' && \
       PROJECT_TABLE_PREFIX=${PROJECT_TABLE_PREFIX}_
  fi

  if [ ! ${PROJECT_TABLE} ] ; then
    # generate default name
    test ! ${PROJECT_TABLE_PREFIX} && PROJECT_TABLE_PREFIX=pt_

    test ! ${PT_PATH_INDEX} && PROJECT_TABLE=${PROJECT}
  fi

  PRJCT_BASENAME=${PROJECT_TABLE_PREFIX}${PROJECT_TABLE}

  return
}

initTables()
{
  # extract the name of the experiment from subPath
  # Explanation: look for EXP_PATH_INDEX in a configuration file

  # we need a real array
  PT_PATH_INDEX=( ${PT_PATH_INDEX//,/ } )

  PT_PATH_INDEX_MAX=100  # exceeds any number of path components

  if [ ${PT_PATH_INDEX[0]} ] ; then
    # note: the highest number points to the most left-side
    # path component
    PT_PATH_INDEX_MAX=0

    local t
    for t in ${PT_PATH_INDEX[*]} ; do
      test ${t} -gt ${PT_PATH_INDEX_MAX} && PT_PATH_INDEX_MAX=${t}
    done
  fi

  mkdir -p ${TABLE_PATH}
  export TABLE_PATH

  # Precedence of path search for tables:
  #
  #   tables/projects/${PROJECT}
  #   tables/projects
  #   tables/${PROJECT}
  #   tables

  # 1) default tables are provided in ${QA_SRC}/tables/projects/PROJECT.
  # 2) a table of the same name provided in ${QA_SRC}/tables gets
  #    priority, thus may be persistently modified.
  # 3) tables from 2) or 1) are copied to ${QA_Results}/tables.
  # 4) Option TABLE_AUTO_UPDATE is the default, i.e. tables in
  #    projects are updated and are applied.
  # 5) 4) also for option USE_STRICT.

  local currPrj=$PROJECT_AS
  local tn name
  for tn in ${tableVars[*]} ; do
    eval name=\$${tn}
    test ${tn} != TABLE_PATH && initT $tn=${name}
  done

  if [ "${QA_CHECK_LIST}" = "${QA_CHECK_LIST//,/}" ] ; then
    initT QA_CHECK_LIST=${QA_CHECK_LIST}
  else
    initTcat QA_CHECK_LIST=${QA_CHECK_LIST}
  fi

  currPrj=CF
  if [ "${CF_CHECK_LIST}" = "${CF_CHECK_LIST//,/}" ] ; then
    initT CF_CHECK_LIST=${CF_CHECK_LIST}
  else
    initTcat CF_CHECK_LIST=${CF_CHECK_LIST}
  fi

# get CF tables
  initT CF_AREA_TYPES=${CF_AREA_TYPES}
  initT CF_STANDARD_NAMES=${CF_STANDARD_NAMES}
  initT CF_STD_REGION_NAMES=${CF_STD_REGION_NAMES}

  return
}

initT()
{
   local table=${1%=*}
   test "${1}" != "${1/=/}" && local value=${1#*=}

   if [ ${value} ] ; then
     value=${value##*/}
   else
     return  # not provided
   fi

   local pDir  # index 0 -> 3 provides precedence
   local prj=$currPrj

   pDir[0]=tables/projects/${prj}
   pDir[1]=tables/projects
   pDir[2]=tables/${prj}
   pDir[3]=tables

   # specialisation
   test ${prj} = CORDEX && initT_CORDEX

   local ix p

   # implicitly and highest: local file and file with absolute path

   if [ ${USE_STRICT:-f} = t ] ; then
      # if USE_STRICT is enabled, then projects[/prj] is required
      p=${QA_HOME}/${pDir[0]}/

   elif [ ! -f ${value} ] ; then
      # a local instance precedes always
      if [ -f ${QA_HOME}/${value} ] ; then
        # explicitly in a sub-dir path
        p=${QA_HOME}/
      else
        for(( ix=0 ; ix < 4 ; ++ix )) ; do

          # scan through the precedence chain
          test -f ${QA_HOME}/${pDir[ix]}/${value} && p=${QA_HOME}/${pDir[ix]}/
        done
      fi
   fi

   # the regular copy part
   if [ -f "${p}${value}" ] ; then
     if ! diff ${p}${value} ${TABLE_PATH}/${value} \
           &> /dev/null ; then
       tryCom \
       cp ${p}${value} ${TABLE_PATH}
     fi

     eval ${table}=${value}
     export ${table}  # note: no value
   fi

   return
}

initTcat()
{
   local table=${1%=*}
   local value=${1#*=}

   test ! ${value} && return  # not provided

   if [ ${USE_STRICT:-f} = t ] ; then
      # if USE_STRICT is enabled, then projects[/prj] is required
      initT ${1##*,}  # only the file in table/project/PROJECT, i.e. the last one
      return
   fi

   # the regular copy part
   local fs=(${value//,/ })

   # cat Files, when younger; the target files must be the first parameter
   local target=${fs[$((${#fs[*]}-1))]##*/}

   catFiles $TABLE_PATH/$target ${fs[*]}

   export ${table}=$target  # note: no value

   test ${fs[0]:0:4} = /tmp && \rm -f ${fs[0]}

   return
}

initT_CORDEX()
{
   local pth=${QA_HOME}/${pDir[0]}

   if [ "$table" = TABLE_RCM_NAME ] ; then
     if [ ${NO_GIT:-f} = f -a ${NO_WGET:-f} = f ] ; then
       if [ -d ${pth}/IS-ENES-Data.github.io ] ; then
         ( cd ${pth}/IS-ENES-Data.github.io && \
           git pull origin ) &> /dev/null
       else
         ( cd ${pth} && \
           git clone  https://github.com/IS-ENES-Data/IS-ENES-Data.github.io ) \
           &> /dev/null
       fi

       test ! -d ${pth}/cordex_specs \
                   && mkdir ${pth}/cordex_specs

       wget --tries=3 -q -N \
       --directory-prefix=${pth}/cordex_specs \
       http://cordex.dmi.dk/joomla/images/CORDEX/RCMModelName.txt \
       &> /dev/null

       # concatenate files, when recently modified or new
       # the target must be the first parameter
       catFiles ${TABLE_PATH}/CORDEX_RCMModelName.txt \
                ${pth}/IS-ENES-Data.github.io/CORDEX_RCMs_ToU.txt \
                ${pth}/cordex_specs/RCMModelName.txt
     else
       catFiles ${TABLE_PATH}/CORDEX_RCMModelName.txt \
                ${pth}/FallBack/CORDEX_RCMs_ToU.txt \
                ${pth}/FallBack/RCMModelName.txt
     fi
   fi

   return
}

##//! Initialisation of the command launcher

intTryComRepeat()
{
  # parse REATTEMPT_LIMIT and SLEEP_TIME

  local rLs
  rLs=( ${REATTEMPT_LIMIT//,/ } )
  unset REATTEMPT_LIMIT

  local period
  declare -a period

  for(( i=0 ; i < ${#rLs[*]} ; ++i )) do
    # two figures?
    local j perd rL

    rL=${rLs[i]}
    perd=0
    for(( j=0 ; j < ${#rL} ; ++j )) ; do
      case ${rL:$j:1} in
        s) perd=${rL:0:j}
           break ;;
        m) perd=$( echo "${rL:0:j} * 60" | bc -l )
           break ;;
        h) perd=$( echo "${rL:0:j} * 3600" | bc -l )
           break ;;
        d) perd=$( echo "${rL:0:j} * 86400" | bc -l )
           break ;;
        w) perd=$( echo "${rL:0:j} * 604800" | bc -l )
           break ;;
        M) perd=$( echo "${rL:0:j} * 2592000" | bc -l )
           break ;;
        y) perd=$( echo "${rL:0:j} * 31536000" | bc -l )
           break ;;
        \?) ;; # not valid; ignore
      esac
    done

    period=( ${period[*]} $perd )
  done

  # defaults
  SLEEP_TIME=1
  REATTEMPT_LIMIT=0
#  period[0]=${period[0]%.*}  # int-rounding

  if [ ${#period[*]} -eq 2 ] ; then
    if [ "${period[1]}" = '0' ] ; then
      SLEEP_TIME=${rLs[1]}
    else
      SLEEP_TIME=${period[1]}
    fi
  fi

  if [ ${#period[*]} -gt 0 ] ; then
    if [ "${period[0]}" = '0' ] ; then
      REATTEMPT_LIMIT=${rLs[0]}  # integer
    else
     if [ $(echo "a=0;if(${period[0]} > $SLEEP_TIME)a=1;a" | bc -l) \
           -eq 1 ] ; then
       REATTEMPT_LIMIT=$( echo "${period[0]} / $SLEEP_TIME" | bc -l)
     else
       REATTEMPT_LIMIT=$( echo "$SLEEP_TIME / ${period[0]}" | bc -l)
     fi

     REATTEMPT_LIMIT=${REATTEMPT_LIMIT%.*}
     test ! ${REATTEMPT_LIMIT} && REATTEMPT_LIMIT=0
    fi
  fi
}

##//! Inquire available disk-space

inqDiskSpace()
{
  test ${DISABLE_INQ_DISK_SPACE:-f} = t && return

  local usedDiskSpace isSubmitted

  # diskUsage.x outputs percentage of used disk space.
  # if this could not be calculated, then return silently
  if ! usedDiskSpace=$( diskUsage.x ${QA_RESULTS} ) ; then
    return
  fi

  # The used disk space must not exceed this threshold %.
  local threshold
  threshold=95

  local total used val

  while : ; do
    # disk has enough space to go on
    test $(echo "a=0;if($usedDiskSpace < $threshold )a=1;a" | bc -l ) -eq 1 && return

    if [ ${isSubmitted:-f} = f ] ; then
      sendSubject="not enough space left on device"

      local text
      text="Available capacity on device below $((100 - threshold)) %"
      text="${text}\ndf  ${QA_RESULTS}:"
      text="${text}\n$( df -h .|head -n 1)"
      text="${text}\n$( df -h .|tail -n 1)"
      text="${text}\nqa-DKRZ stays in a wait loop."

      std_out flush "${text}"
      isSubmitted=t
    fi

    sleep 91
  done

  sendSubject="disk space shortage cleared"
  text="Disk space shortage cleared."
  text="${text}\nqa-DKRZ resumes processing."

  std_out flush "${text}"
}

is_TPUT()
{
  test ${CLOSED_TTY} = t && return 1
  test $isTPUT = f      && return 1

  # reassure that TTY is still valid
  if [ ! -c "$TTY" ] ; then
    CLOSED_TTY=t
    isTPUT=f
    return 1
  fi

  return 0
}

is_TTY()
{
  test ${CLOSED_TTY} = t && return 1

  # reassure that TTY is still valid
  if [ ! -c "$TTY" ] ; then
    CLOSED_TTY=t
    return 1
  fi

  return 0
}

##//! Save configuration information.

logConfiguration()
{
  # don't create log-files
  test ${isShow:-f} = t && return

  # two things happen here. The config file(s), i.e. also a task file,
  # will be copied to the config directory.
  # Also, the names will be noted  in the session log-file, additionally
  # with the command-line call

  # when a session is resumed
  test -e ${SESSION_LOGDIR}/session.prmbl && return

  # a preamble will be copied to all log-files
  local preamble=${SESSION_LOGDIR}/session.prmbl

  # this file is prepended to all exp-log-files
  tryCom \
  echo    '---'                 > $preamble
  echo    '# Log-file of a QA session started by qa-DKRZ' \
                               >> $preamble
  echo    'configuration: '    >> $preamble
  echo -n ' command-line: '    >> $preamble
  echo    "$*"                 >> $preamble

  # save living configuration options
  echo -e ' options: '      >> $preamble

  local i z
  for(( i=0 ; i < ${#keyWordList[*]} ; ++i )) ; do
     eval w="\${${keyWordList[i]}[*]}"
     test -z "$w" && w=t

     echo -n "  ${keyWordList[i]}: " >> $preamble
     if has --char=, "${w}" ; then
       echo "[${w//,/, }]"   >> $preamble
     else
       echo "${w}"           >> $preamble
     fi
  done

  # start: and corresponding date:
#  local rev_0
#  getRevNum rev_0

  log --start

  # make a link between session logdir and task name
#  if [ ${qaCs} ] ; then
#    local p s
#    p=${SESSION_LOGDIR%/*}
#    s=${SESSION_LOGDIR##*/}
#    ln -sf ${SESSION} $p/${qaCs[0]##*/}
#  fi

  return
}

##//! Log annotations to the experiment-logfile
log()
{
  # print execution messages to the experiment-log file

  local s_out  # collects sTxt for output

  local sp
  sp[0]=''
  sp[1]=' '
  sp[2]='  '
  sp[3]='   '
  sp[4]='    '
  sp[5]='     '
  sp[6]='      '
  sp[7]='       '
  sp[8]='        '

  if [ "$1" = '--start' ] ; then
    s_out="start:\n${sp[1]}date: $( date +'%FT%T' )"
    s_out="${s_out}\n${sp[1]}qa-revision: ${QA_REVISION}"
    echo -e "$s_out" >> ${SESSION_LOGDIR}/session.prmbl

    cp ${SESSION_LOGDIR}/session.prmbl ${SESSION_LOGDIR}/session.log

    echo 'items:' >> ${SESSION_LOGDIR}/session.prmbl
    unset sTxt
    return
  fi

  local out
  if [ ${EXP_PATH_INDEX[0]} ] ; then
    getExperimentName ${subPath}
  else
    getExperimentName ${netxFile[0]}
  fi
  out=$EXP_LOGDIR/${CURR_EXP_NAME}.log

  s_out="${s_out} - date: $( date +'%FT%T' )"

#  if [ ${QA_HOST} = $HOSTNAME ] ; then
#  test ${ix} -lt 2 && \
#    echo  "${sp[ix]}date: $( date +'%FT%T' )" >> $out
#  else
#    tryRemote ssh ${QA_HOST} \
#      echo -e ${str} >> $out
#  fi

  # The total output is subdivided into chunks of pmax characters.
  # Effect of \n is preserved.
  local i k str0 str
  local N=70

  for(( i=0 ; i < ${#sTxt[*]} ; ++i )) ; do
    #sTxt: 'I[ - ]text'
    #       ^-- number of leading spaces

#    if [ "${sTxt[i]}" != "${sTxt[i]//:/}" -o ${#sTxt[i]} -lt $N ] ; then
      s_out="${s_out}\n${sp[${sTxt[i]:0:1}]}${sTxt[i]:1}"
      continue
#    fi

    # break a long text into several line
    s_out="${s_out} |"  # preserve lines

    if [ "${sTxt[i]:1:3}" = ' - ' ] ; then
      s_out="${s_out}\n${sp[${sTxt[i]:0:1}]} - |"
      str0="${sTxt[i]:4} }"
    fi

    str=

    while : ; do
      k=0  # necessarily outside the for-loop if the latter is skipped

      if [ ${#str0} -ge $N ] ; then
        # break lines with length > N
        for (( ; k < N ; ++k )) ; do
          if [ "${str0:k:2}" = "\n" ] ; then
            str="${str}${sp[$(( ${sTxt[i]:0:1} +1))]}${str0:0:k}\n"
            str0=${str0:$((k+2))}
            continue 2
          fi
        done
      fi

      if [ $k -eq $N ] ; then
        str="${str}${sp[$(( ${sTxt[i]:0:1} +1))]}${str0:0:N}\n"
        str0=${str0:N}
      else
        str="${str}${sp[$(( ${sTxt[i]:0:1} +1))]}${str0:0:N}"
        break
      fi
    done
    s_out="${s_out}${str}"

  done

  echo -e "${s_out}" >> $out

  test "$1" == '--keep' && return

  unset sTxt

  return
}

log_expMessage()
{
  # print execution messages to the experiment-log file

  # $1: "time-range"
  # $2: "execution message"

  local str

  # extracted name of the experiment from SUB_PATH;
  # see configuration file

  # date and time range
  str="\n$( date +'%F %T' ) "
  str="$str""$1"

#  if [ ${QA_HOST} = $HOSTNAME ] ; then
    tryCom \
    echo -e "${str}" >> $EXP_LOGDIR/${CURR_EXP_NAME}.log
#  else
#    tryRemote ssh ${QA_HOST} \
#      echo -e ${str} >> $EXP_LOGDIR/${CURR_EXP_NAME}.log
#  fi

   return
}

##//! Log annotation to the session-logfile

log_sessMessage()
{
  # print messages to the log file

  test ! ${DEBUG_MANAGER} && voidX

  # date and host
  local k N str0 str

  str0="$( date +'%F %T' ) ${HOSTNAME%%.*}:qa-DKRZ\n"
  str0="${str0}$*"

  # The total output is subdivided into chunqks of pmax characters.
  # Effect of \n is preserved.
  local N
  N=100
  str=

  while : ; do
    k=0  # necessary when skipping the loop

    if [ ${#str0} -ge $N ] ; then
      # break lines with length > N
      for (( ; k < N ; ++k )) ; do
        if [ "${str0:k:2}" = "\n" ] ; then
          str="${str}${str0:0:k}\n"
          str0=${str0:$((k+2))}
          continue 2
        fi
      done
    fi

    if [ $k -eq $N ] ; then
      str="${str}${str0:0:N}\n\t"
      str0=${str0:N}
    else
      str="${str}${str0:0:N}"
      break
    fi
  done

  tryCom \
  echo -e "\n${str}" >> $SESSION_LOGDIR/session.log

  test ! ${DEBUG_MANAGER} && voidX
  return
}

##//! Log current QA version information

mkLinks()
{
  local dest_path=$1
  local subPath=$2
  local src_filename=$3
  local fBase=$4

  local i grfs grf text text2

  local f tmp

  tmp=$( getDateRange ${src_filename} )
  f=${src_filename%.nc}
  f=${f%_${tmp}}

  # Get all names of corresponding genuine qa result files.
  grfs=(
     $(ls ${dest_path}/${subPath}/*${fBase}* \
         2> /dev/null) )

  local is

  tmp=$( getDateRange ${link_filenameBase} )
  link_filenameBase=${link_filenameBase%.nc}
  link_filenameBase=${link_filenameBase%_${tmp}}

  # target and link share the same filename base
  test ${link_filenameBase} = ${f} && is=t

  for grf in ${grfs[*]} ; do
    local name=${grf##*/}

    if [ ${is:-f} = t ] ; then
      test -h ${dest_path}$saveSubPath/$name && continue

      if ln -s -t ${dest_path}$saveSubPath \
            ${link_target_path}/$name &> /dev/null ; then
        text2="${text2}\nQA File:\t${grf##*/}"
      fi
    else
      grf=${grf##*/}
      grf=${grf/${f}/${link_filenameBase}}

      test -h ${dest_path}$saveSubPath/$grf && continue

      cd ${dest_path}$saveSubPath &> /dev/null
      if ln -s ${link_target_path}/$name $grf &> /dev/null ; then
        text2="${text2}\nQA File:\t${grf}"
      fi
      cd - &> /dev/null
    fi
  done

  if [ ${grfs[0]} ] ; then
    sTxt[0]="3data_path: ${PROJECT_DATA}${saveSubPath}"
    sTxt[1]="3caption: 'symbolic link to QA results'"
    sTxt[2]="3text: $((${#grfs[*]}+2))"
    sTxt[3]="3 - qa_linkpath= ${dest_path}${saveSubPath}"
    sTxt[4]="3 - qa_target_path= ${grf[0]%/*}"

    if [ ${#grfs[*]} -gt 1 ] ; then
      local l
      for(( l=0 ; l <  ${#grfs[*]} ; ++l )) ; do
         sTxt[$((l+4))]="3 - qa_file= ${grfs[l]}"
      done
    else
      sTxt[4]="3 - qa_file= ${grfs}"
    fi

    local k n text
    for(( k=0 ; k < ${#sTxt[*]} ; ++k )) ; do
      n=1
      test "${sTxt[k]:1:3}" = ' - '  && n=4

      text="${text}${sTxt[k]:n}\n"
    done
    std_out flush "${text}"
  fi

  return
}

##//! Operate sets of sub-temporal files for a given variable.

##/*!
## Maximum number of sets is equivalent to the number of NUM_EXEC_THREADS.
##*/

operatePipes()
{
  # Variables, i.e. the entire sets of sub-temporal files,
  # are kept in a container (array of indirect references).
  # Maximum number of indirect references equals the maximum
  # of allowed number of execution threads. In the initial phase
  # the container is filled step by step for each call of this
  # function. If all sub-temporal files of a given variable
  # are processed, then the corresponding container item is
  # released and filled with the next variable. Special care
  # has to be taken when the last item of the set of sub-temporal
  # files as well as the last variable.

  local subPath
  local hasFinished=f
  local retVal=1

  if [ $# -gt 0 ] ; then
     subPath=$1
  else
    # drain pipes
    hasFinished=t
    nFcurr=0
    retVal=0
  fi

  # empty subPath for draining the pipes; nothing to refill
  if [ ${subPath} ] ; then
    # find the next file(s); if there is any.
    if \
#trace \
      getNextVariable ${fBase[ix]} ; then

      return $retVal # try for a next one
    fi

    # Any duplicates of variables in case of multiple PROJECT_DATA
    # assignments? Note: all sub-paths are mapped to the same QA_RESULTS
    if [ ${#PROJECT_DATAV[*]} -gt 1 ] ; then
      local k;
      for(( k=0 ; k < nFmax ; ++k )) ; do
        if [ "${fBase[ix]}" = "${nF_name[k]}" ] ; then
          # The if-clause is sufficient. Testing sub-paths allows identical
          # variable names in different sub-paths (not CMIP5 or CORDEX).
          test "${fBase[ix]}" = ${nF_name[k]} && return 0
        fi
      done
    fi

    # update container of indirect references of string arrays.
    # init: direct to new pipes step by step
    # op:   redirect to drained pipes
    local j
    if [  $nFmax -lt ${maxNumExecThreads} ] ; then
      # init:
      nF_PID[${nFmax}]=0
      j=$nFmax
      nFmax=$((nFmax+1))
    else
      # op:
      j=$nFcurr
    fi

    xyz=nFstore${j}
    eval ${xyz}=\(\${nextFile[*]}\)
    eval nFstore[${j}]=${xyz}

#trace \
    if [ ${EXP_PATH_INDEX[0]} ] ; then
      getExperimentName ${subPath}
    else
      getExperimentName ${nextFile[0]}
    fi

#trace \
    getProjectTableName ${subPath}

    nF_EXP[${j}]=$CURR_EXP_NAME
    nF_TP[${j}]=$PROJECT_TABLE
    nF_SUBPATH[${j}]=${subPath}
    nF_name[${j}]=${fBase[ix]}

    if [ "${qa_fl}" ] ; then
      nF_SEQ[${j}]=s
    else
      nF_SEQ[${j}]=f
    fi

    countActivePipes=$(( countActivePipes + 1 ))
  fi

  # purpose of this loop: whenn all allowed execution threads
  # are busy, then wait until any of them is free again
  local op_nap=1
  local host_nap

  while : ; do
    # the index holds the value across the function
    test ${nFcurr} -eq ${nFmax} && nFcurr=0

    for((  ; nFcurr < nFmax ; ++nFcurr )) ; do
      # skip pipe with a running job
      if [ ${nF_PID[nFcurr]} -gt 0 ]  ; then
        if ps -p ${nF_PID[nFcurr]} -o pid= &> /dev/null  ; then
          # there is still an active job for this fBase
          continue
        fi
      elif [ $hasFinished = t ] ; then
        # fade out
        test $countActivePipes -gt 0  && continue

        break 2  # that's it
      fi

      metaV=${nFstore[nFcurr]}[*]
      metaW=${nFstore[nFcurr]}

      p_nF=(${!metaV})
      CURR_EXP_NAME=${nF_EXP[nFcurr]}
      PROJECT_TABLE=${nF_TP[nFcurr]}

      subPath=${nF_SUBPATH[nFcurr]}

      # anything extraordinary in a record of a sub-temporal file must stop
      # the pipe; p_nF -eq 0 means that the pipe is empty
      ls ${QA_RESULTS}/data/${subPath}/qa_lock_*.txt ${notes} &> /dev/null
      local stt=$?

      if [ ${stt} -eq 0 ] ; then
        # no processing due to a lock-file
#        if [ ${PROGRESS_BAR} ] ; then
          local num=${#p_nF[*]}
#        fi
      fi

      if [ ${#p_nF[*]} -eq 0 -o ${#stt} -eq 0 ] ; then
        countActivePipes=$(( countActivePipes - 1 ))
        nF_EXP[${nFcurr}]=
        nF_TP[${nFcurr}]=
        nF_name[${nFcurr}]=
        nF_PID[${nFcurr}]=0
        nF_SUBPATH[${nFcurr}]=
        nF_SEQ[${nFcurr}]=
        unset nFstore[${nFcurr}]

        if [ $hasFinished = t ] ; then
          continue;
        else
          return $retVal # get next variable
        fi
      fi

      nextFile=${p_nF[0]}

      if [ ${nF_SEQ[${nFcurr}]} = 'f' ] ; then
        if [ ${#p_nF[*]} -eq 1 ] ; then
          FILE_SEQUENCE=x # there is only a single file
        else
          FILE_SEQUENCE=f
          nF_SEQ[${nFcurr}]=s
        fi
      elif [ ${#p_nF[*]} -eq 1 ] ; then
         FILE_SEQUENCE=l # last
      else
         FILE_SEQUENCE=s
      fi

      if [ ${#p_nF[*]} -eq 1 ] ; then
        POST_PROC=t
      else
        POST_PROC=
      fi

      if [ ${SHOW_NEXT:-0} -gt 0 ] ; then
        if [ ${SHOW_NEXT} -gt $(( ++fileCount - 1 )) ] ;  then
          # update the container with arrays of filenames
          unset p_nF[0]  # pop from the front

          # store the residual array
          eval ${metaW}=\( \${p_nF[*]} \)
          std_out flush "Path: ${PROJECT_DATA}/${subPath}"
          std_out flush "  File: ${nextFile}"
          continue
        else
          finally
        fi
      fi

      # select a free host and store the name  in variable 'nextHost'
      # returns 0 for success and 1 for no free host found
      host_nap=1  # increment for a sleeping period

      test ! ${DEBUG_MANAGER} && voidX
      while \
#trace \
       ! getHost
      do

#      while ! getHost ; do
#trace \
        sleep $host_nap
        test $host_nap -lt $maxSleep && host_nap=$(( host_nap +1 ))
      done
      test ! ${DEBUG_MANAGER} && voidX

      # check disk space
      if [ ${ENABLE_DISK_SPACE_INQ:-f} = t ] ; then
#trace \
        inqDiskSpace
      fi

      if [ ${SHOW_NEXT:-f} = t ] ; then
        std_out flush "Next: ${subPath} ${nextFile}"
        finally
      fi

#trace \
      callQaExecutor ${nextFile}

      # store the corresponding pid
      nF_PID[${nFcurr}]=${currPID}

#      if [ ${PROGRESS_BAR} ] ; then
        # get number of data files for progress estimation
#      fi

      displayStatusLine ${#nextFile} "\rNEXT File: ${nextFile}"

      # limit the number of executions
      if [ ${NEXT:-0} -gt 0 -a ${NEXT:-0} -eq $(( ++fileCount )) ] ;  then
#trace \
        wait_fnct

        if [ ${FLOW_TRACE:-f} = t ] ; then
          FLOW_TRACE_EXIT=t
          return $retVal
        fi

        return 0  # unconditional
      fi

      # update the container with arrays of filenames
      unset p_nF[0]  # pop from the front

      # store the residual array
      eval ${metaW}=\( \${p_nF[*]} \)

#      if [ ${NO_STATUS} = f  ] ; then
#        if [ ${SIMPLE_STATUS_LINE:-f} = t ] ; then
#          # get number of data files for progress estimation

#          displayStatusLine ${#nextFile[nF_IX]} "\rNEXT File: ${nextFile[nF_IX]}"
#        fi
#      fi

      if [ ${#DEBUG_MANAGER} -gt 1 ] ; then
        wcRes=($( wc -l ${DEBUG_MANAGER}.${dbgCycle}))
        # cycle after every block of 1000000 lines
        if [ ${wcRes[0]} -gt 1000000 ] ; then
          set +x
          exec 2<&7 7<&-
          exec 7<&2
          exec 2>${DEBUG_MANAGER}.$((++dbgCycle))
          set -x
        fi
      fi
    done

    # all pipes are busy
    if [ ${countActivePipes} -eq ${nFmax} -o $hasFinished = t ] ; then
      test ${nFmax} -eq 0 && return $retVal  # pipes have never been filled

#trace \
      sleep $op_nap
      test $op_nap -lt $maxSleep && op_nap=$(( op_nap +1 ))
    fi

    # container still not initially filled
    if [ $hasFinished = f -a $nFmax -lt ${maxNumExecThreads} ] ; then
      return $retVal
    fi
  done

  return $retVal
}

rmBlock()
{
  test $# -lt 2 && return

  local file=$1
  local pattern=$2

  # get all lines with line numbers having ' file: pattern'
  local nums num sz i

  declare -a nums
  nums=($(grep -n "[[:space:]]*file:[[:space:]]*${pattern}" $1 ))

  # extract the numbers
  nums=(${nums[*]#file:})
  nums=(${nums[*]%${pattern}*})
  nums=(${nums[*]%:})

  # remove all blocks by default. $2==num keeps the num last occurrences
  sz=$(( ${#nums[*]} -1))
  test $3 && sz=$((sz-$3))
  test ${sz} -lt 0 && return

  for(( i=sz ; i > -1  ; --i )) ; do
    num=$(( ${nums[i]} -1 ))

    sed  -i "$num,/status:/ d" $file
  done

  return
}

runExample()
{
  # running an example for CORDEX
  dir=$(pwd)
  dir=${dir%/example}/example

  test "${EXAMPLE_PATH}" && dir=${EXAMPLE_PATH}/example

  test ${dir:0:1} != '/' && dir=$(pwd)/$dir

  if ! mkdir -p ${dir} &> /dev/null ; then
    echo "could not mkdir ${dir}, please use option --example=path"
    exit
  fi

  cd $dir

  \rm -rf results config.txt data tables qa-test.task

  echo "make examples in $dir " > $TTY
  echo "make qa_test.task " > $TTY

  # prepare the example, if not done, yet
  cp $QA_SRC/example/templates/qa-test.task .
  sed -i "s%PROJECT_DATA=data%PROJECT_DATA=${dir}/data%" \
         qa-test.task
  sed -i "s%QA_RESULTS=results%QA_RESULTS=${dir}/results%" \
         qa-test.task

  # data
  echo "make data " > $TTY
  tar --bzip2 -xf ${QA_SRC}/example/templates/data.tbz
  fs=( $( find data -name "*.txt" ) )

  if which ncgen &> /dev/null ; then
    for f in ${fs[*]} ; do
      ncgen -x -k 3 -o ${f%txt}nc $f
      \rm -f $f
    done
  else
    echo "building data in example requires the ncgen utility"
    exit
  fi

  echo "run"  > $TTY
  echo "$QA_SRC/scripts/qa-dkrz -m --work=$dir -f qa-test.task" > $TTY

  exec $QA_SRC/scripts/qa-dkrz -m --work=$dir -f qa-test.task

  return
}

##//! Send annotations to the list of email recipients.

sendEMail()
{
  if [ ! ${EMAIL_TO[0]} ] ; then
     return
  fi

  local sendSub
  sendSub="QA ${PROJECT} ${CURR_EXP_NAME}: ${sendSubject}"

  # activate backslash escaped chars
  local sendT
  sendT="$( echo -e $sendText )"

  eval ${MAIL} -s \"\$sendSub\"  ${EMAIL_TO[*]} <<!
$sendT
!

  return
}

rmEmptyPaths()
{
  local subPath
  while read -a subPath ; do
    rmdir -p ${QA_RESULTS}/data/${subPath[1]} &> /dev/null
  done < ${pathListFile}

  return
}

setKWL()
{
  # store keywords, no values
  local key=${1%%=*}
  test "${1}" != "${1/=/}" && local value=${1#*=}

  # was key already defined?
  for(( i=0 ; i < ${#keyWordList[*]} ; ++i )) ; do
     if [ "${keyWordList[i]}" = "$key" ] ; then
      if [ ${value} ] ; then
        local asdf
        eval asdf=\$${key}
        if [ "$asdf" != "$value" ] ; then
          eval $key="$value"
        fi
      fi

      return
    fi
  done

  # add key to the list
  keyWordList[${#keyWordList[*]}]=$key

  return
}

splitAtRegExp()
{
  # $1 : a path

  set -f

  # split selected path into components
  local items=( ${1//\// } )

  splitRE_0=

  # look for an alpha-numeric sub-path leading a selected path
  local i
  for(( i=0 ; i < ${#items[*]} ; ++i )) ; do
    if expr match "${items[i]}" "[[:alnum:]_-]\{${#items[i]}\}" &> /dev/null ; then
      # only accept valid paths
      splitRE_0=${splitRE_0}/"${items[i]}"
    else
      break
    fi
  done

  local slash=
  for(( ; i < ${#items[*]} ; ++i )) ; do
    splitRE_1=${splitRE_1}${slash}${items[i]}
    local slash=/
  done

  set +f

  return 0
}

##//! Launcher of annotations

##/*!
## Determination where annotations go to: experiment _logfile,
## session-logfile, email, and/or terminal.
##*/

std_out()
{
  # if a tty device is connected, then output immediately,
  # else collect contents and print to a default file and/or
  # send by email.
  test $# -eq 0 && return

  if [ "$1" = ttyOnly ] ; then
    if is_TTY ; then
       shift
       echo -e -n "$*" > $TTY
    fi
    return
  fi

  if [ "$1" = add  ] ; then
    # only collect items
    shift
    outputText[${#outputText[*]}]="$*"

    return
  fi

  if [ "$1" = flush ] ; then
    shift
    test $# -gt 0 && outputText[${#outputText[*]}]="$*"

    # nothing to flush
    test ${#outputText[*]} -eq 0 && return
  fi

  local j str0

  # flush
  if [ ${#outputText[*]} -eq 0 -a $# -eq 0 ] ; then
    return
  fi

  # email
  # print to session logfile
  sendText=
  for(( j=0 ; j < ${#outputText[*]} ; ++j )) ; do
    sendText="${sendText}${outputText[j]}"
  done

  if [ ${SESSION_LOGDIR} ] ; then
    log_sessMessage "${outputText[*]}"
  fi

  if is_TTY ; then
     shift
     echo -e -n "${sendText}\n" > $TTY
  else
    if [ ${EMAIL_TO[0]} ] ; then
     sendEMail
    fi
  fi

  # neither email nor session logfile. Store in dir NoDevice
#  if [ ${isSent} = f ] ; then
#    # str0 gets the filename for undeliverables
#    if mkdir -p $QA_SRC/NoDevice &> /dev/null ; then
#      str0="undeliv_$( date +'%FT%T' )_${HOSTNAME%%.*}".txt
#      echo "$str0" >> $QA_SRC/NoDevice/$str0

#      for(( j=0 ; j < ${#outputText[*]} ; ++j )) ; do
#        echo -e -n "${outputText[j]}" >> $QA_SRC/NoDevice/$str0

#      for(( j=0 ; j < ${#outputText[*]} ; ++j )) ; do
#        echo -e -n "${outputText[j]}" >> $QA_SRC/NoDevice/$str0
#      done
#    fi
#  fi

  unset outputText

  return
}

taskSum()
{
  test ${NO_SUMMARY:-f} = t && return

  local cvr prj qrs tcl ers
  test ${PROJECT}    && prj="-P ${PROJECT}"
  test ${QA_RESULTS} && qrs="-r ${QA_RESULTS}"

  if [ ${TABLE_PATH} ] ; then
    tcl="-t ${TABLE_PATH}/${QA_CHECK_LIST}"
    tcfcl="-c ${TABLE_PATH}/${QA_CHECK_LIST}"
    test ${FIND_NOT_DELIVERED:-t} = t &&
      cvr="-s ${TABLE_PATH}/${TABLE_VAR_REQ}"
  fi

  if [ ${EMAIL_SUMMARY} ] ; then
    ers="${EMAIL_SUMMARY[*]}"
    ers=" -e ${ers// /,}"
  fi


  # multiple threads, but a maximum of 2
  local exp_ix=0
  local pidBufMax=2
  local pidBuf
  local isStart=f
  local buf_ix=0
  local i

  for(( i=0 ; i < pidBufMax ; ++i )) ; do
    pidBuf[i]=''
  done

  while [ ${exp_ix} -lt ${#EXP_NAMES[*]} ] ; do
    for(( i=0 ; i < pidBufMax ; ++i )) ; do
      if [ "${pidBuf[i]}" ] ; then
        if ! ps -p ${pidBuf[i]} -o pid= &> /dev/null  ; then
          # there is still an active job for this fBase
          isStart=t
          break
        fi
      else
        isStart=t
        break
      fi
    done

    if [ ${isStart} = t ] ; then
      /bin/bash ${QA_SRC}/scripts/taskSummary ${DEBUG_X} \
        -p ${QA_RESULTS}/check_logs --src=$QA_SRC \
        ${cvr} ${ers} ${prj} ${qrs} ${tcl} ${EXP_NAMES[exp_ix]} &

      pidBuf[i]=$!
      isStart=f
      exp_ix=$((exp_ix+1))
    else
      sleep 1
    fi
  done

  wait
  return
}

terminate()
{
  isTERM=t
  finally
  exit
}

testFileLink()
{
  # Purpose: when the file of the current path is
  # a symbolic link, then make links to corresponding QA results.
  # If corresponding QA results don't exist, the append the subpath
  # to the genuine data (Note: D A T A ).
  # If the path to the genuine data is LOCKed, then remove the lock.

  # Note: only links of files within ${subPath}
  # are taken into account. A symbolic link of the prefixed
  # ${PROJECT_DATA} path is always dereferenced.

  local src_filename link_target_path

  # Note: multiple filenames are allowed, but all
  # would be ascociated with the same QA result file.
  # Thus,considering the first one is sufficient

  # Take into account not only a qa-result file but, also new
  # associated files, e.g. freqDist. These could be added
  # after having established the link to the qa result file.

  # dereferenced link
  deref_link link_target_path ${PROJECT_DATA}/${subPath}/$nextFile

  src_filename=${link_target_path##*/}
  link_target_path=${link_target_path%/*.nc}

  if [ ! ${link_target_path} ] ; then
    # this should not happen
    sendSubject="No valid link detected from source"

    sTxt[0]="3text: 1"
    sTxt[1]="3 - link detection failed for: ls -l ${PROJECT_DATA}/${subPath}/$nextFile"

    std_out flush "${sTxt[1]:4}"

    sendEMail
    return 0
  fi

  local saveSubPath=${subPath}
  local dest_path=${QA_RESULTS}/data

  if [ "${link_target_path:0:1}" = '/' ] ; then
    # a link to the outside of PROJECT_DATA will always be dereferenced
    test "${link_target_path:0:${#PROJECT_DATA}}" != ${PROJECT_DATA} && return 1

    # adjust for a link with an absolute path
    link_target_path=$QA_RESULTS/data${link_target_path#${PROJECT_DATA}}

    subPath=${link_target_path#${QA_RESULTS}/data/}
  else
    # Any relative path?
    subPath=${link_target_path}

    local tmp_subPath
    if [ ${saveSubPath:0:1} = '/' ] ; then
      tmp_subPath=${saveSubPath:1}
    else
      tmp_subPath=${saveSubPath}
    fi

    while [ ${subPath:0:1} = '.' ] ; do
      subPath=${subPath#*/}
      tmp_subPath=${tmp_subPath%/*}
    done

    subPath=/${tmp_subPath}/${subPath}
  fi

  # qa the genuine data
  tryCom \
  mkdir -p ${QA_RESULTS}/data/${subPath}

# point to the genuine filename from here
  local ix=0
  local f fBase tmp

  tmp=$( getDateRange ${src_filename} )
  f=${src_filename%.nc}
  f=${f%_${tmp}}
  fBase[ix]=$f

#  getFilenameBase
  operatePipes ${subPath}

#trace \
  checkClosedMessages

  # link to genuine qa results
  mkLinks ${dest_path} ${subPath} ${src_filename} ${fBase[ix]} &

  return
}

testLocks()
{
  # $1: fBase[ix]
  # $2: qa_*.nc if any

  # apply rules, clearings, and test for qa_note files
  if \
#trace \
  applyRules $1 ; then
    return 0  # not selected
  fi

  # conditions for clearing are described in the configuration file
  if [ ${CLEAR} ] ; then
#trace \
    if [ ${EXP_PATH_INDEX[0]} ] ; then
      getExperimentName ${subPath}
    else
      getExperimentName $1
    fi

    # if CLEAR=only or SHOW_CLEAR was set, then try another variable
    if clear ; then
      return 0
    fi
  fi

  if \
#trace \
  checkLockFile $1 $2 ; then
#    if [ ${PROGRESS_BAR} ] ; then
#      local num=$( ls -d ${PROJECT_DATA}/${subPath}/${1}*.nc \
#                    | grep -c . )
#    fi

    return 0  # is blocked
  fi

  return 1
}

testPathLink()
{
  # Purpose: when the current path is
  # a symbolic link, then make links for the QA results, too.
  # Input parameter: subPath
  # Return 0 for a link

  # Note: only a link of a directory within ${subPath}
  # is taken into account. A symbolic link to the outside
  # is
  # A symbolic link of the prefixed
  # ${PROJECT_DATA} path is always dereferenced.

  if [ $# -eq 0 ] ; then
     return 1
  fi

  local dest_path

  dest_path=$QA_RESULTS/data${1}

  local link_target_path

  # test path components. Note: pc starts with a '/'
  local pc
  pc=${1%/}

  while [ "${pc}" != "${pc%/*}" ] ; do

    if [ ! -h ${PROJECT_DATA}$pc ] ; then
       pc=${pc%/*}  # try the preceding component
       continue  # not a symbolic link
    fi

    # dereferenced link
    deref_link link_target_path ${PROJECT_DATA}$pc

    if [ ! ${link_target_path} ] ; then
       # this should not happen
       sendSubject="No valid link detected from source"

       sTxt[0]="3text: 1"
       sTxt[1]="3 - Link detection failed for: ls -l ${PROJECT_DATA}$pc"

       std_out flush "${sTxt[1]:4}"

       sendEMail
       continue
    fi

    # a link to the outside of PROJECT_DATA will be dereferenced
    if [ "${link_target_path:0:1}" = '/' -a \
         "${link_target_path:0:${#PROJECT_DATA}}" != ${PROJECT_DATA} ] ; then
       return 1
    fi

    # the dir where to place the link must exist.
    test ! -e $QA_RESULTS/data${pc%/*} && return 0  # try again later

    # is there already a link in the qa dir tree?
    if [ -e "$QA_RESULTS/data${pc}" ] ; then
       # is the link still the one it should be?
       local dest_lnk

       # dereferenced link
       deref_link dest_lnk  ${QA_RESULTS}/data$pc

       # link exists; nothing has changed
       if [ "$link_target_path" = "$dest_lnk" ] ; then
         return 0
       fi
    fi

    # we don't care if a broken link is produced; this may get
    # valid in a later iteration.
    ln -sf ${link_target_path} $QA_RESULTS/data${pc}

    local text
    text="Symbolic link for a sub-tree"

    if [ ${link_target_path:0:1} = / ] ; then
      sTxt[0]="3text: 1"
      sTxt[1]="3 - $QA_RESULTS/data${pc} --> ${link_target_path}"
    else
      sTxt[0]="text: 2"
      sTxt[1]="3 - common_path: $QA_RESULTS/data${pc%/*}"
      sTxt[2]="3 - link: ${pc##*/} --> ${link_target_path}"
    fi

    test ${#text} -gt 28 && log_sessMessage "$text"

    return 0
  done

  return 1
}

timer()
{
  # on normal execution, this function is closed externally in time
  limit=10
  for(( i=0 ; i < limit ; ++i )) ; do
    if ! ps -p $1 -o pid= &> /dev/null  ; then
      # there is no more active job
      return 0
    fi

    sleep 1
  done

  kill -TERM $1
  return 1
}

##//! Flow tracing of the session

##/*!
## Just for debugging or efficiency considerations.
##*/

trace()
{
  local ret

  if [ ${FLOW_TRACE:-f} = f ] ; then
    eval $*
    return $?
  fi

  trc_curr_depth=$(( trc_curr_depth + 1 ))

  local i j index str t0 t1 token count

  # estimating trace itself
  t0=$(unixTime.x dec)

  count=0
  while [ $count -lt 5 ] ;  do  # a workaround for erroneous expr exit value
  # find the function name, perhaps embedded
  if expr match "$*" '[[:alpha:]]*=' &> /dev/null ; then
    # variabel=( $(fnctName ... )
    token=$( expr match "$1" '[[:alpha:]]*=*[^[:alpha:]]*\([[:alpha:]]\+\)' )
  elif expr match "$*" '[^[:alpha:]]' &> /dev/null ; then
    # $(fnctName ... )
    token=$( expr match "$*" '[^[:alpha:]]*\([[:alpha:]]\+\)' )
    test ! ${token} && token="$1"
  else
    token="$1"  # a plain function was called
  fi

    count=$(( count + 1 ))
    test ${#token} -gt 1 && break
  done;

  for(( index=0 ; index < ${#trc_name[*]} ; ++index )) ; do
    test ${trc_name[index]} = trc_${token} && break
  done

  if [ ${index} = ${#trc_name[*]} ] ; then
    trc_name[$index]=trc_${token}
    trc_time[$index]=0.
    trc_count[$index]=0
    trc_depth[$index]=$trc_curr_depth
  fi

  t1=$(unixTime.x dec 2> /dev/null)
  trc_time[0]=\
$(echo "${trc_time[0]} + $t1 - $t0 - $traceCalibTime" \
   | bc -l 2> /dev/null)
  trc_count[0]=$(( trc_count[0] + 1 ))

  # time measurement of called function
  t0=$(unixTime.x dec)
  eval $*
  ret=$?
  t1=$(unixTime.x dec)

  trc_time[$index]=\
$(echo "${trc_time[$index]} + $t1 - $t0 - $traceCalibTime" | bc -l 2> /dev/null)
  trc_count[$index]=$(( trc_count[$index] + 1 ))
  trc_depth[$index]=$trc_curr_depth

  trc_curr_depth=$(( trc_curr_depth - 1 ))

  test ${FLOW_TRACE_EXIT:-f} = t && exit

  return $ret
}

traceCalibration()
{
  local prg

  if [ ${HOSTNAME} = surge ] ; then
    prg="${QA_SRC}/bin/unixTime.x dec"
  elif [ ${HOSTNAME:0:3} = liz ] ; then
    prg="${QA_SRC}/bin_l/unixTime.x dec"
  elif [ ${HOSTNAME:0:4} = pass ] ; then
    prg="${QA_SRC}/bin_p/unixTime.x dec"
  elif [ ${HOSTNAME:0:4} = bliz ] ; then
    prg="${QA_SRC}/bin_b/unixTime.x dec"
  else
    echo "traceCalibration: executable unixTime.x not found"
    exit
  fi

  local t0 t1

  traceCalibTime=0
  trc_curr_depth=0

  t0=$( $prg )
  trace :
  t1=$( $prg )

  traceCalibTime=$(echo "${t1} -${t0}" | bc -l 2> /dev/null)
  traceStartTime=$( $prg )

  return
}

tracePrint()
{
  # part of the elapsed time used in trace itself will be removed

  local i j tab resid sum out total sz
  sum=0.
  out=qa_flowtrace.lst

  total=$(unixTime.x dec)
  total=$(echo "$total - ${traceStartTime}" | bc -l 2> /dev/null )

  echo -e "Function\t\tdepth\tcount\ttime [s]" > $out
  echo -e "--------\t\t-----\t---------------" >> $out

  sz=${#trc_name[*]}

  # accumulated time [%]
  for(( i=1 ; i < sz ; ++i )) ; do
    # skip secondary processes
    test ${trc_depth[i]} -gt 1 && continue

    sum=$(echo "$sum + ${trc_time[i]}" | bc -l 2> /dev/null )
  done

  # residual time
  local tmp
  tmp=$(echo "$total - ${sum}" | bc -l )
  trc_time[${#trc_time[*]}]=$tmp

  # elapsed time
  trc_time[${#trc_time[*]}]=${total}

  # position of the decimal point of the accumulated times
  local pre
  pre=0
  for(( i=1 ; i < ${#trc_time[*]} ; ++i )) ; do
     for((j=0 ; j < ${#trc_time[i]} ; ++j )) do
       if [ "${trc_time[i]:j:1}" = '.' ] ; then
         test $j -gt $pre && pre=$j
         break
       fi
     done
  done

  # formatting of the acc. times
  local trm
  trm=6
  for(( i=1 ; i < ${#trc_time[*]} ; ++i )) ; do
     for((j=0 ; j < ${#trc_time[i]} ; ++j )) do
       if [ "${trc_time[i]:j:1}" = '.' ] ; then
         # trim decimal digits
         trc_time[$i]=${trc_time[i]:0:$(( j + trm))}
         local k
         for(( k=0 ; k < pre - j ; ++k )) ; do
           trc_time[$i]=" ${trc_time[i]}"
         done
         break
       fi
     done
  done

  for(( i=1 ; i < sz ; ++i )) ; do
    if [ ${#trc_name[i]} -lt 12 ] ; then
      tab='\t\t\t'
    elif [ ${#trc_name[i]} -lt 20 ] ; then
      tab='\t\t'
    else # [ ${#trc_name[i]} -lt 28 ] ; then
      tab='\t'
    fi

    echo -e -n "${trc_name[i]:4}"       >> $out
    echo -e -n "${tab}${trc_depth[i]}"  >> $out
    echo -e -n "\t${trc_count[i]}"      >> $out
    echo -e   "\t${trc_time[i]}"        >> $out

  done

  echo -e "--------\t\t \t----------------" >> $out
  tab='\t\t'

  echo -e "residual time${tab}\t\t${trc_time[sz]}" >> $out

  echo -e "elapsed time${tab}\t\t${trc_time[$((sz+1))]}" >> $out
}

##//! Command launcher

##/*!
## Several commands are passed to this launcher making processing
## more robust against interruptions of the file system.
##*/

tryCom()
{
  test ! ${DEBUG_MANAGER} && voidX

  # leading options:
  # a) return the status after trying:   get_status
  # b) set temporary sleep period:       set_sleep
  # c) set temporary REATTEMPT_LIMIT:    set_limit

  # $*:   command [with args]

  # Examples:
  # 1) tryCom 'eval echo -e qa-DKRZ.${2} >> qwer/qwer'
  # 2) for f in $(tryCom ls -d *) ; do ... ; done
  # 3) tryCom 'eval echo -e qa-DKRZ.${2} >> qwer/qwer'
  # There is a dependency on bash's "noglob" setting

  local i arg tCStatus
  local countAttempts=0
  local n_shift=0

  local limits=$REATTEMPT_LIMIT
  local t_slice=$SLEEP_TIME
  local getStatus=f

  for(( i=1 ; i <= $# ; ++i )) ; do
    arg=${!i}
    if [ "${arg}" = 'get_status' ] ; then
       getStatus=t
       n_shift=$(( n_shift + 1 ))
       continue
    elif [ "${arg:0:10}" = 'set_limit=' ] ; then
       limits=${arg#*=}
       n_shift=$(( n_shift + 1 ))
       continue
    elif [ "${arg:0:10}" = 'set_sleep=' ] ; then
       t_slice=${arg#*=}
       n_shift=$(( n_shift + 1 ))
       continue
    else
      break
    fi
  done

  test ${n_shift} -gt 0 && shift ${n_shift}

  local retVal

  while : ; do
    $* 2> /dev/null # execute the command

    tCStatus=$?
    if [ $tCStatus -eq 0 ] ; then
      retVal=0
      break
    fi

    # for a configuration defined period
    if [ $((countAttempts++)) -lt $limits ] ; then
       sleep $t_slice
       continue
    fi

    # number of allowed attempts exceeded.

    # it is ok to have failed, so just return
    if [ ${getStatus} = t ] ; then
      retval=$tCStatus
      break
    fi

    # Try a last time to get the error message.
    local failed
    failed="$( $* 2>&1 )"

    # for instance rm returns an error text with embedded ` and '
    failed=$( echo "$failed" | sed 's%`%%g' |sed "s%'%%g")

    std_out add "Failed command in qa-DKRZ: $*"
    std_out add "\n${failed}"

    sendSubject="command failed after ${limits} reattempts"
    std_out flush

    finally

    retVal=1
    break
  done

  test ! ${DEBUG_MANAGER} && voidX
  return $retVal
}

voidX()
{
  # toggle between set -x and set +x in a way that
  # restores the original setting after calling twice

  if [ ${isSetX:-t} = t ] ; then
    test "$(set -o |grep xtrace | awk '{print $2}')" = off && return

    # first call
    isSetX=on
  fi

  # restore previous setting
  if [ ${isSetX} = off ] ; then
    set -x
    isSetX=on
  else
    set +x
    isSetX=off
  fi

  return
}

wait_fnct()
{
  test ${SHOW_CALL:-f} = t && return

  # a getSelectedPath process is still running; kill it
  if ps -p ${getPathPID:-0} -o pid= &> /dev/null  ; then
     kill -9 $getPathPID &> /dev/null
     wait $getPathPID &> /dev/null
  fi

  local count=0
  local i isAnyAlive

  while : ; do

    isAnyAlive=f

    for(( i=0 ; i < nFmax ; ++i )) ; do
       # skip pipe with a running job
       if [ ${nF_PID[i]} -gt 0 ]  ; then
         if ps -p ${nF_PID[i]} -o pid= &> /dev/null  ; then
           # there is still an active job for this fBase
           isAnyAlive=t
           sleep 1

           if [ ${isTERM:-f} = t -o $((count++)) -gt ${ZOMBIE_LIMIT} ] ; then
             # kill immediately of after a while
             kill -TERM ${nF_PID[i]} &> /dev/null
             wait ${nF_PID[i]} &> /dev/null
           fi
         fi
       fi
    done

    test $isAnyAlive = f && break
  done

  return
}

##//! Determine the path to QA-0.4/scripts from $0


##//! Entry to this script

##/*!
## Definition of traps, init() and check().
##*/

##main()
##{
######## main ############
umask 002

# store the tty, if any
if tty -s ; then TTY=$(tty) ; fi

# test for nohup

#sleep 10

QA_CONFIG=qa-config
QA_FILE_EXECUTER=qa-exec-check

if ! which git &> /dev/null ; then
  NO_GIT=t
fi

if ! which wget &> /dev/null ; then
  NO_WGET=t
fi

rootPID=$$

init $*

test ${FLOW_TRACE:-f} = t && traceCalibration

trap terminate TERM
trap finally EXIT

test ${SHOW_EXP:-f} = t  && getAllExps && exit

### the inifinit loop: over all experiments again and again ####
check

##}
