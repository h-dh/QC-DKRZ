#! /bin/bash

##/*! \file qaExecution.h
## \brief Script launches checks for particular files
##*/

##//! Analysis of output by executable of qA_main.pp

##/*!
## Annotations are redirected corresponding to configuration settings.
##*/

analyseExec()
{
  # no progress
  if [ ${status} -eq 63 ] ; then
     finally
     exit 0
  fi

  # lock processing
  if [ $status -gt 1 -a ${isNormalExecution:-f} = t ] ; then
    local nm=${ncFile##*/}
    nm=${nm%.nc}
    if [ -e qa_note_${nm}.txt ] ; then
      mv qa_note_${nm}.txt qa_lock_${nm}.txt
    fi
  fi

  # print data_path:, file:, and result_path:
  sTxt[${#sTxt[*]}]='--standard'

  if [ ${isNormalExecution:-f} = t ] ; then

    # any qa-notifications?
    # nothing to do for 2, 3
    if [ $status -eq 4 ] ; then

      sTxt[${#sTxt[*]}]='text: EMERGENCY STOP'

      isSignalTerm=t  # emergency stop, if not intercepted
      issueMail=t

    elif [ $status -gt 4 ] ; then

      sTxt[${#sTxt[*]}]="text: qA-${PROJECT_AS}.x: run-time error. \
Note: possibly due to a bug in NetCDF 4.1.2 F90 lib. \
However, the check was successful."

      issueMail=t
    fi

  else

    # uncontrolled system exception, i.e. a crash
    y_impact=L2
    y_caption='segmentation fault'
    y_tag=SF
    status=5
    initLog

    sessText="qA-${PROJECT_AS}.x: run-time error, exit status: ${status}"

    local s_out="${ans}qA-${PROJECT_AS}.x: run-time error"

    s_out="${s_out}\nfile: ${NEXT_FILE}"
    s_out="${s_out}\ndata_path: ${PROJECT_DATA}/${SUB_PATH}"
    s_out="${s_out}\nresult_path: ${QA_RESULTS}/data/${SUB_PATH}"
    s_out="${s_out}\n\nTried:\n$(cat param_file_$$.txt)"

    local nm=${ncFile##*/}
    nm=${name%.nc}
    tryCom echo -e "$s_out" >> qa_lock_${nm}.txt

    issueMail=t
    isSignalTerm=t  # emergency stop, if not intercepted
  fi

 return
}

##//! Bind an external function to determine the checksum of a data file.

bind_checksum()
{
  fs=( ${*##*/} ) # just the filename

  local arr item cs force type

  arr=( ${CHECKSUM//,/ } )

  for item in ${arr[*]} ; do
    if [ ${item} = force ] ; then
      force=--force
      continue
    fi

    if [ ${item} = t ] ; then
      type='--type=md5'
    else
      type="--type=${item}"
    fi
  done

  local cs_table

  if [ "${CHECKSUM_DIR}" ] ; then
     if [ ${CHECKSUM_DIR:0:1} = '/' ] ; then
       cs_table="-p ${CHECKSUM_DIR}"
     else
       cs_table="-p ${QA_RESULTS}/${CHECKSUM_DIR}"
     fi
  else
     cs_table="-p ${QA_RESULTS}/cs_table"
  fi

  local email
  if [ "${EMAIL_TO[*]}" ] ; then
     email="${EMAIL_TO[*]}"
     email="-m ${email// /,}"
  fi

  # calulcate the checksum
  ${QA_SRC}/scripts/checkSum $type  $force \
      ${CHECKSUM_FILE:+-w}  $email $cs_table \
      ${EXP_NAME:+-x} ${EXP_NAME} \
      -P ${PROJECT_DATA} -S ${SUB_PATH#/} ${fs[*]}

  return
}

callPing()
{
  # no ping necessary
  test "$1" == "$HOSTNAME" && return 0

  if [ ${PING_ENABLED:-f} = t ] ; then
    if $myPing -c 1 $1 &> /dev/null ; then
      return 0
    else
      return 1
    fi
  fi

  return 0
}

##//! Remove temporary back-up files after successful execution.


##/*!
## Purpose: overcome system crashes
##*/

clearBackUp()
{
  local isClearQABackUp isClearFdBackUp
  isClearQaBackUp=f
  isClearFdBackUp=f

  if [ $status -lt 4 ] ; then
    isClearQaBackUp=t
    isClearFdBackUp=t
  else
    # If nothing has changed, then clear back-up.
    if cmp z_qa_${name}.nc qa_${name}.nc &> /dev/null ; then
      isClearQaBackUp=t
    fi
    if [ -d Z_fd_${name} ] ; then
      isClearFdBackUp=t
      local f
      for f in $(ls Z_fd_${name} 2> /dev/null ) ; do
        if ! cmp Z_fd_${name}/$f $f &> /dev/null ; then
          isClearFdBackUp=f
          break
        fi
      done
    fi
  fi

  # a rule of thumb mechanism to secure files against corruption,
  # even in case of a system-crash: Part II:
  if [ ${isClearQaBackUp} = t ] ; then
   \rm -f z_qa_${name}.nc &> /dev/null
  fi
  if [ ${isClearFdBackUp} = t -a -d "Z_fd_${name}" ] ; then
    \rm -rf Z_fd_${name}   &> /dev/null
  fi
}

##//! Close communication with qa-DKRZ

##/*!
## Communication is done by files.
##*/

clearProcPool()
{
  # clear the blocking by the message file in ProcPool
  if [ -d  $PROC_POOL/session ] ; then
    if [ ${DISTRIBUTED_FS:-f} = f ] ; then
       tryCom mv $PROC_POOL/$PROC_FILE.lock $PROC_POOL/$PROC_FILE.closed
    else
       tryRemote ssh ${QA_HOST}  \
         mv $PROC_POOL/$PROC_FILE.lock $PROC_POOL/$PROC_FILE.closed
    fi
  fi
}

##//! THE QA of a netCDF file

runQA()
{
  # this is the ultimately last check
  if [ "$QA_RESULTS/data/${SUB_PATH}" = "${PROJECT_DATA}$SUB_PATH" ] ; then
    sTxt[0]="3qaExecution: Path of QA_RESULTS/data/SUB_PATH \
and PROJECT_DATA/SUB_PATH must not be identical"
    log

    sendEMail
    isSignalTerm=t  # emergency stop
  fi

  # destination for results
  test ${SHOW_CALL:-f} = f && tryCom cd $QA_RESULTS/data/${SUB_PATH}

  if [ ! -s ${ncFile} ] ; then  # no file found
    # this might happen, if someone has deleted
    # the file in the meanwhile.
    local str
    str="NetCDF File ${ncFile} not found.\n"
    str="${str}Exit."

    sTxt[0]="3qaExecutor: ${str}"
    log

    sendEMail
    return
 fi

 name=${ncFile##*/}

 if [ "${NEXT_PERIOD}" ] ; then
   name=${name%_${NEXT_PERIOD}.nc}
 else
   name=${name%.nc}
 fi

 # very special: gather tracking_ids of files; that's all
 if [ ${TRACKING_ID_ONLY:-f} = t ] ; then
   writeTrackingID
   return
 fi

 # secure files against corruption,
 # even in case of a system-crash: Part I:
 if [ ${SHOW_CALL:-f} = f ] ; then
   # Note: if the first attempt to write into such a file
   # was interrupted by a system crash, then there is no
   # back-up file available, but a corrupt qa-nc file.
   # This has already been tested and cleared by qa-DKRZ.

   # save backup
   if [ -e qa_${name}.nc ] ; then
     tryCom cp -a qa_${name}.nc z_qa_${name}.nc
   fi
   if ls fd_* &> /dev/null ; then
     mkdir Z_fd_${name}
     tryCom cp -a fd_${name}* Z_fd_${name}
   fi
 fi

 # define parameter setting for qA.x; stored in file param_file_$$.txt
#trace \
 setParameter

if [ ${SHOW_CALL:-f} = t ] ; then
  if [ -c "$TTY" ] ; then
     echo param_file_$$.txt
     echo -e "$par_str"
  fi
  return
fi


 # Be nice: check, whether load is lower than two of the three limits.
 if [ "${WORK_AT_LOW_LOAD:-f}" = 't' ] ; then
   if [ ${QA_HOST} != $HOSTNAME ] ; then
     while : ; do
       upTime=( $(uptime) )
        # for linux and solaris identical
       i=$(( ${#upTime[*]} - 3 ))
       loadShort=${upTime[i++]}
       load15min=${upTime[++i]}
       bcVal1=$( echo "a=0;if(${loadShort%,} < 1.5)a=1;a" | bc -l)
       bcVal2=$( echo "a=0;if(${load15min} < 1.0)a=1;a" | bc -l)
       if [ ${bcVal1} -eq 1 -a ${bcVal2} -eq 1 ] ; then
         break
       fi
       sleep 67
     done
   fi
 fi

 # the Hans-Luthardt Extreme Value Detection
 if [ "${HLEVD:-f}" = t  ] ; then
   getHLEVD $ncFile ${name%%_*}
 fi

#trace \
  run

  # Secure files against corruption,
  # even in case of a system-crash: Part II:
#trace \
  clearBackUp

#trace \
  analyseExec

  # Exceptions are reported. Also, if error-files of non-QA-objects
  # are found, these are moved/merged to/with a/the qa_note_...txt.
#trace \
  reportFindings

  if [ ${isNormalExecution:-f} = t ] ; then
    # only a brief note to the session message file
    echo -e "\n$( date +'%F %T' )\nFile: ${ncFile##*/}\nStatus=${status}" \
         >> $PROC_POOL/session/$SESSION.$$.log
  fi

  # skip when only spaces?
  if $( echo "$ans" | grep -q '[^[:space:]]\+' ) ; then
    # split ans lines to sTxt
    local pos0=0
    local pos1

    if [ "${ans}" ] ; then
      local ix=${#sTxt[*]}  # num of text lines later
      sTxt[${ix}]="7text:"

      local cnt=1
      for(( pos1=0 ; pos1 < ${#ans} ; ++pos1 )) ; do
        test "${ans:pos1:1}" != '\' && continue
        test "${ans:pos1:2}" != '\n' && continue

        sTxt[${#sTxt[*]}]="7 - ${ans:pos0:$((pos1-pos0))}"
        pos0=$((pos1+2))
        pos1=$((pos1+1))
#         cnt=$(( cnt +1 ))
      done
      sTxt[${#sTxt[*]}]="7 - ${ans:pos0:$((pos1-pos0))}"
#     sTxt[${ix}]="${sTxt[ix]}${cnt}"  # append INTEGER
    fi
  fi

  sTxt[${#sTxt[*]}]="3status: ${status}"
  log  --keep

  test ${issueMail:-f} = t && sendEMail

  return
}

##//! Clearings before exit.

finally()
{
  # $1 keyword to be added to the message

  test ${SHOW_CALL:-f} = f && \rm -f param_file_$$.txt

  local sendT text

  # notify the end of this instance

  # any running process to be killed?
  if [ "${runPID:-0}" ] ; then
    if ps -p ${runPID} -o pid= &> /dev/null  ; then
       kill -9 $runPID &> /dev/null
       wait $runPID &> /dev/null
       isExit=t
    fi
  fi

  if [ ${isTERM:-f} = t ] ; then
     # clear current results
     \rm -f *
     if [ ${isDeadLocked:-f} = t ] ; then
       echo "killed after reaching the ZOMBIE_LIMIT=${ZOMBIE_LIMIT}s" \
            > qa_lock_${name}.txt
     fi
  fi

  # clear the blocking by the message file in ProcPool
  clearProcPool

  # clear the data path, when empty
# rmdir -p ${QA_RESULTS}/data/${SUB_PATH} &> /dev/null

  if [ ${DEBUG_EXECUTOR:-f} = t ] ; then
    set +x
    exec 2<&7 7<&-
  fi

  test ${isSignalTerm:-f} = t && signalParent TERM

  test ${isExit:-f} = t && exit 0

  return
}

##//! Format annotations.

formatText()
{
  # format text ready for email of session logging

#  pauseX

  local where=$1
  shift

  # date and host
  local k n N str0 str isWrap

  str0="$( date +'%F %T' ) ${HOSTNAME%%.*}:qaExecutor.${where}"
  str0="${str0}\nFile:\t\t${NEXT_FILE}"
  str0="${str0}\nData path:\t$PROJECT_DATA/${SUB_PATH}"
  str0="${str0}\nQA result path: $QA_RESULTS/data/${SUB_PATH}"
#  str0="${str0}DRS tree:\t${SUB_PATH#/}\n"

  str0="${str0}\n$*"

  # The total output is subdivided into chunks of pmax characters.
  # Effect of \n is preserved.
  N=100
  str=

  while : ; do
    k=0  # necessary when skipping the loop

    if [ ${isWrap:-f} = t ] ; then
      n=$(( N - 6 ))
    else
      n=$N
    fi

    if [ ${#str0} -ge $n ] ; then
      # wrap lines with length > N
      for (( ; k < n ; ++k )) ; do
        if [ "${str0:k:2}" = "\n" ] ; then
          str="${str}${str0:0:k}\n"
          str0=${str0:$((k+2))}
          isWrap=f
          continue 2
        fi
      done
    fi

    # the last line
    if [ ${#str0} -le $n ] ; then
      str="${str}${str0}"
      break

    # sub-lines length equals N
    elif [ $k -eq $n -a "${str0:k:2}" = "\n" ] ; then
      str="${str}${str0:0:n}"
      str0=${str0:n}

    # wrap line
    else
      str="${str}${str0:0:n}\n      "
      str0=${str0:n}
      isWrap=t
    fi
  done

#  pauseX

  formattedText=${str}
}

getChecksum()
{
  # Not only checksum, but also creation_date and tracking_id.

  # extension corresponding to the checksum method
  ext=md5

  if [ "${CHECKSUM}" != t ] ; then
    ext=${CHECKSUM%sum}
    ext=${ext##*/}
  fi

  if [ ${CS_STAND_ALONE:-f} = t ] ; then
    CS_TABLE=$CS_TABLE/${NEXT_FILE%.nc}.$ext
  else
    CS_TABLE=$CS_TABLE/${EXP_NAME}.$ext
  fi

  local i line
  if line=( $( grep $NEXT_FILE $CS_TABLE 2> /dev/null ) ) ; then
    checkSum=${line[0]}

    # Appends ' Q' to the end of the corresponding line.
    sed -i "/${NEXT_FILE}/ s/$/ Q/" $CS_TABLE

    for(( i=1 ; i < ${#line[*]} ; ++i )) ; do
      if [ ${line[i]%=*} = creation_date ] ; then
        creationDate=${line[i]#*=}
      elif [ ${line[i]%=*} = tracking_id ] ; then
        trackingID=${line[i]#*=}
      fi
    done
  fi

  return
}

##//! Hans-Luthard-Extreme-Value-Determination

##/*!
## Not used. Very time consuming.
##*/

getHLEVD()
{
  # calculate (max-min)/std
  # optional: mask result for each gridpoint with
  #           (max-min)/std > num x std
  local inF var outF

  inF=$1
  var=$2
  outF=${1##*/}
  outF=${outF%.nc}_hlevd

  local x_in

  if [ ${HLEV_DETREND:-f} = t ] ; then
    cdo detrend $inF $outF.det.nc &> /dev/null
    x_in=$outF.det.nc
  else
    x_in=$inF
  fi

  cdo timmin $x_in $outF.min.nc &> /dev/null
  cdo timmax $x_in $outF.max.nc &> /dev/null
  cdo timstd $x_in $outF.std.nc &> /dev/null
  cdo sub $outF.max.nc $outF.min.nc $outF.dif.nc &> /dev/null
  cdo div $outF.dif.nc $outF.std.nc $outF.res.nc &> /dev/null
  cdo gtc,${HLEVD_THRESHOLD:-1} $outF.res.nc \
         $outF.TH-${HLEVD_THRESHOLD:-1}.nc &> /dev/null

  mv $outF.res.nc $outF.nc

 \rm -f $outF.det.nc $outF.min.nc $outF.max.nc $outF.std.nc $outF.dif.nc

  # test whether the mask file check is negative, i.e. no outlier
  local sum
  sum=$( cdo output -fldsum -selvar,$var \
     $outF.TH-${HLEVD_THRESHOLD:-1}.nc 2> /dev/null )

  local is
  is=f

  if [ ${sum} -gt 0  ] ; then
    sTxt[0]="3qaExecution: $outF.nc: outlier above ${HLEVD_THRESHOLD:-1} x sigma"
    log
    is=t
  fi

  # keep files?
  test ${HLEVD_DELETE_FILE:-t} = t && \rm -f $outF.res.nc

  if ! [ ${is} = t -a ${HLEVD_KEEP_THRESHOLD_FILE:-f} = t ] ; then
    \rm -f $outF.TH-${HLEVD_THRESHOLD:-1}.nc
  fi

  return
}

##//! Initialisation of this run.

init()
{
  # set a default
  test -c "$TTY" && echo HOSTNAME=${HOSTNAME}
  test ${ZOMBIE_LIMIT:-f} = f && ZOMBIE_LIMIT=3600

  PARENT_EXP_ID=none
  PARENT_EXP_RIP=none

  # No check for correct and full parameters.
  if [ ! "${PROC_POOL}" ] ; then
    test -c "$TTY" && echo 'No access to PROC_POOL'
    sTxt[${#sTxt[*]}]='text: no access to PROC_POOL'

    log --keep
    sendEMail

    isSignalTerm=t  # emergency stop
    finally
    return 0
  fi

  # Used for messaging between qa-DKRZ and this executor.
  # PROC_FILE is for locking, shall be removed later.

  # lock
  if [ ${DISTRIBUTED_FS:-f} = f ] ; then
     tryCom mv $PROC_POOL/$PROC_FILE $PROC_POOL/$PROC_FILE.lock
  else
     tryRemote ssh ${QA_HOST} \
       mv $PROC_POOL/$PROC_FILE $PROC_POOL/$PROC_FILE.lock
  fi

  if [ ! -r $PROC_POOL/$PROC_FILE.lock ] ; then
    test -c "$TTY" && echo "PROC_POOL-file $PROC_POOL/$PROC_FILE not found"
    sTxt[${#sTxt[*]}]="text: $PROC_POOL/$PROC_FILE no such file."

    log --keep
    sendEMail

    finally
    return 0
  fi

  #scan for keywords provided in a file
  while read -r item; do
    keyW=${item%%=*}
    eval ${keyW}="${item#*=}"
  done < $PROC_POOL/$PROC_FILE.lock

  PATH=${IMPORTED_PATH}:$PATH

  # Distributed file system?This is the qa-DKRZ host.
  if [ ${DISTRIBUTED_FS:-f} = t ] ; then
    test ${QA_HOST} = $HOSTNAME && DISTRIBUTED_FS=f
  fi

  # path to the netCDF file
  ncFile=${PROJECT_DATA}/${SUB_PATH}/${NEXT_FILE}

  # execution log-file
  EXEC_LOG=${NEXT_FILE%.nc}.log

  # debugging?
  if [ ${DEBUG_EXECUTOR:-f} = t ] ; then
    exec 7<&2
    exec 2>${EXEC_LOG}
    set -x
  fi

  fName=${NEXT_FILE%.nc}

  # Are the executables in QA_BIN applicable?
  if ! unixTime.x &> /dev/null ; then
    sTxt[${#sTxt[*]}]="text: qaExecutor:\nBinaries are not applicable in  ${IMPORTED_PATH}"

    log --keep
    sendEMail

    isSignalTerm=t  # emergency stop
    finally
    return 0
  fi

  if ! tryCom get_status test -f "${ncFile}" ; then
    sTxt[${#sTxt[*]}]='--standard'
    sTxt[${#sTxt[*]}]="text: file ${ncFile} not found by qaExecutor."

    log --keep
    sendEMail

    isSignalTerm=t  # emergency stop
    finally
    return 0
  fi

  # no sense to check parent relations when there is a non-regular
  # time stepping going on.
  if [ ${NON_REGULAR_TIME_STEP:-f} = t ] ; then
    PARENT_EXP_ID=none
    PARENT_EXP_RIP=none
  fi

  status=1 # a preset default

  return 1
}

##//! Init annotation logging
initLog()
{
  local ix=${#sTxt[*]}

  sTxt[$((ix++))]="3events:"
  sTxt[$((ix++))]="3 - event:"
  sTxt[$((ix++))]="7caption: \'${y_caption}\'"
  sTxt[$((ix++))]="7impact: ${y_impact}"
  sTxt[$((ix++))]="7tag: \'${y_tag}\'"

  local i
  for(( i=0 ; i < ${#y_text[*]} ; ++i )) do
    sTxt[$((ix++))]="${y_text[i]}"
  done
  unset y_text

#  sTxt[$((ix++))]="3status: ${y_status:-0}"
#  y_status=

  return
}

##//! Log annotations to the check-log file

log()
{
  # print execution messages to the experiment-log file
  local sp
  sp[0]=''
  sp[1]=' '
  sp[2]='  '
  sp[3]='   '
  sp[4]='    '
  sp[5]='     '
  sp[6]='      '
  sp[7]='       '
  sp[8]='        '

  local s_out=" - date: $( date +'%FT%T' )"

  local i j k l str0 str
  local N=70

  for(( i=0 ; i < ${#sTxt[*]} ; ++i )) ; do
    if [ "${sTxt[i]}" = '--standard' ] ; then
      s_out="${s_out}\n${sp[3]}file: ${NEXT_FILE}"
      s_out="${s_out}\n${sp[3]}data_path: ${PROJECT_DATA}/${SUB_PATH}"
      s_out="${s_out}\n${sp[3]}result_path: ${QA_RESULTS}/data/${SUB_PATH}"
      break
    fi
  done

  for(( i=0 ; i < ${#sTxt[*]} ; ++i )) ; do
    #sTxt: 'I[ - ]text'
    #       ^-- number of leading spaces
    if [ "${sTxt[i]}" = '--standard' ] ; then
      continue
    fi

    # provide a default for the space index
    local ix=${sTxt[i]:0:1}
    if ! test ${ix:-0} -gt 0 &> /dev/null ; then
       ix=7
    fi

#    if [ ${#sTxt[i]} -lt $N -o "${sTxt[i]:1:3}" = ' - ' ] ; then
      s_out="${s_out}\n${sp[ix]}${sTxt[i]:1}"
      continue
#    fi

    # break a long text into several line
    s_out="${s_out} |"  # preserve lines

    if [ "${sTxt[i]:1:3}" = ' - ' ] ; then
      s_out="${s_out}\n" # ${sp[ix]}"
      str0="${sTxt[i]:4}"
    else
      str0="${sTxt[i]}"
    fi
    str=

    while : ; do
      k=0  # necessary when skipping the loop

      if [ ${#str0} -ge $N ] ; then
        # break lines with length > N
        for (( ; k < N ; ++k )) ; do
          if [ "${str0:k:2}" = "\n" ] ; then
            str="${str}${sp[$((ix +1))]}${str0:0:k}\n"
            str0=${str0:$((k+2))}
            continue 2
          fi
        done
      fi

      if [ $k -eq $N ] ; then
        str="${str}${sp[$((ix +1))]}${str0:0:N}\n"
        str0=${str0:N}
      else
        str="${str}${sp[$((ix +1))]}${str0:0:N}"
        break
      fi
    done
    s_out="${s_out}${str}"

  done

  # items are separated by newlines
  echo -e "${s_out}" > $PROC_POOL/experiments/${EXP_NAME}.$$.log

  test "$1" == '--keep' && return

  unset sTxt

  #left=log
  return
}

##//! Log time consumption for the current check

logTime()
{
  # $1: real-time  $2: CPU-time   $3: status

  # reduce number of decimals
  local rT=${1%.*}
  local dec=${1#*.}
  rT=${rT}.${dec:0:2}

  local cT=${2%.*}
  dec=${2#*.}
  cT=${cT}.${dec:0:2}

  test ! -e $EXP_LOGDIR/${EXP_NAME}.time && \
     echo -e "  R   U TIME[s]\tExit\tFile" \
        > $EXP_LOGDIR/${EXP_NAME}.time

   echo -e "${rT} ${cT}\t${3}\t${ncFile##*/}" \
      >> $PROC_POOL/experiments/${EXP_NAME}.$$.time
}

#relaySig()
#{
#  # relay a received signal
#  if [ ${#watchFnctPID} -gt 0 ] ; then
#    if  ps -p ${watchFnctPID} -o pid= &> /dev/null  ; then
#       kill -s TERM ${watchFnctPID}
#    fi
#  fi

#  if [ ${#qaFnctPID} -gt 0 ] ; then
#    if  ps -p ${qaFnctPID} -o pid= &> /dev/null  ; then
#       kill -s TERM ${qaFnctPID}
#    fi
#  fi

#  if [ ${#parentPID} -gt 0 ] ; then
#    if  ps -p ${parentPID} -o pid= &> /dev/null  ; then
#       isSignalTerm=t  # emergency stop
#    fi
#  fi

#  exit
#}

##//! Parse annotations from the qa_main.cpp run on standard output.

parseOutput()
{
  # exchange preceding ';' by newline
  local p0 tmp str
  local j l
  str="${ans[*]}"

  unset ans

#  pauseX

  # xtract embedded string: KEY-BEG any text KEY-END
  local is key keys mess strX strY
  keys=( PERIOD CHECK CPU EMAIL REAL STATUS SUBJECT FLAG )

  while : ; do  # for keys with multiple occurrence
    is=f
  for key in ${keys[*]} ; do
    is=t

    strY=${str%%${key}-BEG*} # frontal residuum
    test ${#strY} -eq ${#str} && continue  # key not found

    mess=${str#*${key}-BEG}
    mess=${mess%%${key}-END*}
    stripSurrounding mess ' ;'

    strX=${str%%${key}-BEG*} # frontal residuum
    test ${#strX} -eq ${#str} && strX=
    strX=${strX}${str#*${key}-END} # the backward residum
    test ${#strX} -eq ${#str} && strX=

    str=${strX}

    if [ ${key} = STATUS ] ; then
      isNormalExecution=t
      status=$mess
      test ${status} -gt 0 && issueMail=t
    elif [ ${key} = SUBJECT ] ; then
      sendSubject="${str:p0:$((l-p0))}"
      issueMail=t
    elif [ ${key} = EMAIL ] ; then
      issueMail=t
      test ${#mess} -gt 0 && sendText="${sendText}${mess}"
    elif [ ${key} = REAL ] ; then
      realTime=$mess
    elif [ ${key} = CPU ] ; then
      cpuTime=$mess
    elif  [ ${key} = CHECK ] ; then
      parseKey CHECK
    elif  [ ${key} = PERIOD ] ; then
      parseKey PERIOD
    elif  [ ${key} = FLAG ] ; then
      parseKey FLAG
    else
      continue
    fi

    test ${#strX} -eq 0 && break 2

    # test for another multiple key
    test "${strX}" != "${strX#*${key}-END}" \
         && continue 2

  done

    test $is = t && break
  done

#  pauseX

  \rm -f out_${name}.txt  # output-file by the run
  return
}

parseKey()
{
  test $# -gt 0 && key=$1

  if [ ${key} = CHECK ] ; then
    local arr=( ${mess} )
    sTxt[${#sTxt[*]}]="3check:"
    if [ ${#arr[*]} -eq 8 ] ; then
      sTxt[${#sTxt[*]}]="4${arr[0]} ${arr[1]}"
      sTxt[${#sTxt[*]}]="4${arr[2]} ${arr[3]}"
      sTxt[${#sTxt[*]}]="4${arr[4]} ${arr[5]}"
      sTxt[${#sTxt[*]}]="4${arr[6]} ${arr[7]}"
    fi

    # checksum, creation_date and tracking_id, if available
    getChecksum
    test ${#checkSum}     -gt 0 && sTxt[${#sTxt[*]}]="3checksum: $checkSum.${ext}"
    test ${#creationDate} -gt 0 && sTxt[${#sTxt[*]}]="3creation_date: $creationDate"
    test ${#trackingID}   -gt 0 && sTxt[${#sTxt[*]}]="3tracking_id: $trackingID"

  elif [ ${key} = PERIOD ] ; then
    local arr=( ${mess} )
    sTxt[${#sTxt[*]}]="3period:"
    if [ ${#arr[*]} -eq 3 ] ; then
      sTxt[${#sTxt[*]}]="4begin: ${arr[0]}"
      sTxt[${#sTxt[*]}]="4end: ${arr[2]}"
    elif [ ${#arr[*]} -eq 2 ] ; then
      if [ ${arr[0]} = '-' ] ; then
        sTxt[${#sTxt[*]}]="4begin: miss"
        sTxt[${#sTxt[*]}]="4end: ${arr[1]}"
      else
        sTxt[${#sTxt[*]}]="4begin: ${arr[1]}"
        sTxt[${#sTxt[*]}]="4end: miss"
      fi
    else
      sTxt[${#sTxt[*]}]="4begin: miss"
      sTxt[${#sTxt[*]}]="4end: miss"
    fi
  elif [ ${key} = FLAG ] ; then
    if [ ${isFlagged:-f} = f ] ; then
      # could contain several lines; extract them
      local e0=${#sTxt[*]}
      sTxt[${e0}]="3events:"  # num of counts later
      isFlagged=t
    fi

    # replace " by '
    local i
    for(( i=0 ; i < ${#mess} ; ++i )) ; do
       test "${mess[i]}" = '"' && mess[i]=\'
    done

    # sX contains the residuum left after extraction of current string
    local sX=${mess%%CAPT-BEG*} # frontal residuum
    test ${#sX} -eq ${#mess} && sX=
    sX=${sX}${mess#*CAPT-END} # the backward residum
    test ${#sX} -eq ${#mess} && sX=

    local caption=${mess#*CAPT-BEG}
    caption=${caption%%CAPT-END*}
    test "${caption:0:1}" = ' ' && caption=${caption:1}

    local impact="${mess%%:*}"

    mess=$sX

    local tag=${impact#*-}
    impact=${impact%-*}

    sTxt[${#sTxt[*]}]="3 - event:"
    sTxt[${#sTxt[*]}]="7caption: '${caption}'"
    sTxt[${#sTxt[*]}]="7impact: $impact"
    sTxt[${#sTxt[*]}]="7tag: \'$tag\'"

    sX=${mess#*TXT-BEG}
    sX=${sX%%TXT-END*}
    test ${#sX} -eq ${#mess} && sX=
    stripSurrounding sX ' ;'

    if [ ${#sX} -gt 0 ] ; then
      sTxt[${#sTxt[*]}]="7text:"

      # multiple lines are separated by ';'
      local p0=0
      local p1
      for(( p1=0 ; p1 < ${#sX} ; ++p1 )) ; do
        if [ "${sX:p1:1}" == ';' ] ; then
          sTxt[${#sTxt[*]}]='7 - '"${sX:p0:$((p1-p0))}"
          p0=$((p1+1))
        fi
      done
      sTxt[${#sTxt[*]}]='7 - '"${sX:p0:$((p1-p0))}"
    fi
  fi

  return
}

pauseX()
{
  # toggle between set -x and set +x in a way that
  # restores the original setting after calling twice

  if [ ${isSetX:-t} = t ] ; then
    test "$(set -o |grep xtrace | awk '{print $2}')" = off && return

    # first call
    isSetX=on
  fi

  # restore previous setting
  if [ ${isSetX} = off ] ; then
    set -x
    isSetX=on
  else
    set +x
    isSetX=off
  fi

  return
}

reportFindings()
{
  local i nm
  nm=${ncFile##*/}
  nm=${nm%.nc}

  # any type of error/warning file for current netCDF file
  local fs
  fs=( $( ls [^tid_]*_${nm}.txt 2> /dev/null) )

  # no notification
  test ${#fs[*]} -eq 0 && return

  # gather non-qa_note-file temporarily
  for f in ${fs[*]} ; do
    test "${f:0:7}" = qa_note  && continue  # skip qa_note... file
    test "${f:0:7}" = qa_lock  && continue  # skip qa_lock... file

    tryCom cat "$f" >> qa_lock_${nm}.txt
    tryCom \rm $f
  done

  if [ -e qa_lock_${nm}.txt ] ; then
    # mv contents of note file to a lock file, if there is any.
    tryCom cat qa_lock_${nm}.txt >> qa_note_${nm}.txt
    tryCom mv qa_note_${nm}.txt qa_lock_${nm}.txt
    qaExceptionFile="qa_lock_${nm}.txt"
  else
    test -e qa_note_${nm}.txt && \
      qaExceptionFile="qa_note_${nm}.txt"
  fi

  return
}

##//! Run the executable of qa_main.cpp

run()
{
  local cmdText
  cmdText="$NICE qA-${PROJECT_AS}.x  --file=param_file_$$.txt"

  sessText="run: ${cmdText}\n"

  # +++++++++++++ run the QA executable
  ${cmdText} > out_${name}.txt &
  runPID=$!
  wait_fnct $runPID
  # ++++++++++++++++++++++++++++++++++

  # read output of the run
  ans=$(<out_${name}.txt)

#trace \
  parseOutput

  # store elapsed real and user time; determined during the run
  test ${LOG_CPU_TIME:-f} = t && logTime $realTime $cpuTime $status
}

##//!Send annotations to the list of email recipients.

sendEMail()
{
  if [ ${isIgnoreOutlierTest:-f} = t \
          -o ${#EMAIL_TO[*]} -eq 0 ] ; then

     test "$1" != '--keep' && unset sTxt

     return
  fi

  if which ${MAIL} &> /dev/null ; then
    # mail or mailx

    ${MAIL} -s "QA: ${ncFile##*/}" ${EMAIL_TO[*]} << EOF
$(cat ${qaExceptionFile} )
EOF

  elif which mutt &> /dev/null ; then

    mutt -s "QA: ${ncFile##*/}" -- ${EMAIL_TO[*]} << EOF
$(cat ${qaExceptionFile} )
EOF

  fi


  return
}

##//! Prepare input paramters of qa_main.cpp

##/*!
## Note: there is a specific format for the frame-program.
##*/

setParameter()
{
  # path to the netCDF file
  par_str="-p ${PROJECT_DATA}/${SUB_PATH}"

  # all files of the family
#  for ncFile in ${ncFiles[*]} ; do
    par_str="${par_str}\n-f ${ncFile##*/}"
#  done

  # path to the tables (have to reside in the same dir)
  par_str=${par_str}"\n-t ${TABLE_PATH}"

  # log CPU time
  if [ ${LOG_CPU_TIME:-f} = t ] ; then
    par_str=${par_str}" --cpu-time}"
  fi

  # parameters for general annotation handling
  set_X_par
  par_str="${par_str}\n${par}"

  # parameters for CF convention checks
  set_CF_par
  par_str="${par_str}\n${par}"

  # define parameter for the input file object in $
  set_IN_par
  par_str="${par_str}\n${par}"

  # perform a quality check?
  if [ "${QA:-on}" = 'on' ] ; then
    set_qa_par # construct directive sequence for QA
    par_str="${par_str}\n${par}"
  fi

  # any time control?
  if [ "${#TIME_LIMIT}" -gt 0 ] ; then
    set_tc_par # construct directive sequence for TC
    par_str="${par_str}\n${par}"
  fi

  # freqency distribution, if requested
  if [ "${FREQ_DIST:-f}" = 't' ] ; then
    set_fd_par # construct directive sequence for qA
    par_str="${par_str}\n${par}"
  fi

  echo -e "$par_str" > param_file_$$.txt

  return
}

##//! Input paramters of the Annotation class
set_CF_par()
{
  # construct directives for the exception handling.
  set_X_par 1  # X::1

  # combine the two
  par=${par}"\n"CF::0:IN::0:X::1

  test ${#CF_STANDARD_NAMES} -gt 0 && \
    par=${par}":cFSN=${CF_STANDARD_NAMES}"

  test ${#CF_AREA_TYPES} -gt 0 && \
    par=${par}":cFAT=${CF_AREA_TYPES}"

  test ${#CF_STD_REGION_NAMES} -gt 0 && \
    par=${par}":cFSRN=${CF_STD_REGION_NAMES}"

  test ${#CF} -gt 0 && \
    par=${par}":cF=${CF}"

  test ${#CF_FOLLOW_RECOMMENDATIONS} -gt 0 && \
    par=${par}':fR'

  return
}

##//! Input paramters of the FreqDist class.
set_fd_par()
{
  # construct directive sequence for qA. Called from run
  par="FD::0:useAreaWeight"

  # output: saved as fd-build-file by default

  # expediently only for debugging
  if [ ${FD_PLAIN:-f} = t ] ; then
    par=${par}":printPlain"
    return
  fi
  if [ ${FD_BARS:-f} = t ] ; then
    par=${par}":printBars"
    return
  fi

  # A fd-build-file of the same variable at destination has priority.
  # Second choice is a fd-build-file or fd-prop-file in a specified
  # path. Third choice is an explict statement of properties.
  # Default: automatic determination of fd properties.

  # Directive for saving the output to a build-file
  # Note: the effective name will have a time interval appended.
  par=${par}":s=fd_${name}.build"

  if [ "${FD_TIME_PART}" ] ; then
    par=${par}":part=${FD_TIME_PART}"
  fi

  # Properties of the freq. dist. Note: current dir is destination.
  local files

  if files=( $( ls fd_${name}*.build 2> /dev/null ) ) ; then
    # Rule 1: rebuild, i.e continue a FD
    par=${par}":r=${files[0]}"
  elif [ "${FD_PROPERTY_PATH}" ] ; then
    if files=( $(ls ${FD_PROPERTY_PATH}/fd_${name}*.build 2> /dev/null) )
    then # Rule 2a
      par=${par}":rp=${files[0]}"  #read properties
    elif files=( $(ls ${FD_PROPERTY_PATH}/fd_${name}*.prop 2> /dev/null) )
    then # Rule 2b
      par=${par}":rp=${files[0]}"  #read properties
    fi
  elif [ "${FD_EXPLICIT_PROPS}" ] ; then  # rule 3
    local props
    props=( ${FD_EXPLICIT_PROPS//\// } )
    par=${par}":w=${props[0]}@i=${props[1]}"
  fi
  # Rule 4 by default
}

##//! Input paramters of the InFile class
set_IN_par()
{
  # construct directive sequence for in. Called from run
  par=IN::0:CF::0:X::0

  test ${ARITHMETIC_MEAN:-f} = t && \
    par=${par}":aM"

  test ${DISABLE_INF_NAN:-f} = t && par=${par}":dIN"

  if [ "${EXCLUDE_VARIABLE}" ] ; then
    # convert array to comma-separated list
    EXCLUDE_VARIABLE="${EXCLUDE_VARIABLE[*]}"
    EXCLUDE_VARIABLE="${EXCLUDE_VARIABLE// /,}"

    par=${par}":eV=${EXCLUDE_VARIABLE}"
  fi

  # grep specific flags in order to discard
  if grep '^Infinite' $TABLE_PATH/$QA_CHECK_LIST 2> /dev/null | grep -q D ; then
     par=${par}":dIN"
  fi
}

##//! Input paramters of the QA class

set_qa_par()
{
 local s
 local i tmp

 par=QA::0:IN::0:X::0
 s=:

 par=${par}":f=qa_$name.nc"

 if [ ${APPLY_MAXIMUM_DATE_RANGE:-f} = t ] ; then
   par=${par}"${s}"aMDR
 elif [ "${APPLY_MAXIMUM_DATE_RANGE}" ] ; then
   par=${par}"${s}"aMDR=${APPLY_MAXIMUM_DATE_RANGE}
 fi

 if [ ${CHECK_MODE:-f} != f ] ; then
   par=${par}"${s}"cM=${CHECK_MODE[0]}
   for(( i=1 ; i < ${#CHECK_MODE[*]} ; ++i )) ; do
     par=${par}",${CHECK_MODE[i]}"
   done
 fi

 test ${DATA_IN_PRODUCTION:-f} = t && \
   par=${par}"${s}"dIP

 test ${DISABLE_CONSISTENCY_CHECK:-f} = t && \
   par=${par}"${s}"dCC

 test ${DISABLE_TIME_BOUNDS_CHECK:-f} = t && \
   par=${par}"${s}"dTB

 if [ "${EXCLUDE_ATTRIBUTE}" ] ; then
   # convert array to comma-separated list
   EXCLUDE_ATTRIBUTE="${EXCLUDE_ATTRIBUTE[*]}"
   EXCLUDE_ATTRIBUTE="${EXCLUDE_ATTRIBUTE// /,}"

   par=${par}"${s}eA=${EXCLUDE_ATTRIBUTE}"
 fi

 test ${#FILE_SEQUENCE} -gt 0 && \
   par=${par}"${s}"fS=${FILE_SEQUENCE}

 test ${#FREQUENCY} -gt 0 && \
   par=${par}"${s}"fq=${FREQUENCY}

 test ${#FREQUENCY_POSITION} -gt 0 && \
   par=${par}"${s}"fqp=${FREQUENCY_POSITION}

 test ${IGNORE_REF_DATE_ACROSS_EXP:-f} = t && \
   par=${par}"${s}"iRDAE

 test ${IGNORE_REFERENCE_DATE:-f} = t && \
   par=${par}"${s}"iRD

 test ${#NEXT_RECORDS} -gt 0 && \
   par=${par}"${s}"nextRecords=${NEXT_RECORDS}

 test ${NON_REGULAR_TIME_STEP:-f} = t && \
   par=${par}"${s}"nRTS

 if [ "${OUTLIER_TEST}" ] ; then
   tmp=
   OUTLIER_TEST="${OUTLIER_TEST[*]}"
   for(( i=0 ; i < ${#OUTLIER_TEST} ; ++i )) ; do
      test "${OUTLIER_TEST:i:1}" = '{' -o "${OUTLIER_TEST:i:1}" = '}' \
         && tmp=${tmp}\\
      tmp=${tmp}${OUTLIER_TEST:i:1}
   done
   par=${par}"${s}"oT="${tmp// /,}"
 fi

 test ${PARENT_EXP_ID:-f} != f && \
   par=${par}"${s}"pEI=${PARENT_EXP_ID}

 test ${PARENT_EXP_RIP:-f} != f && \
   par=${par}"${s}"pER=${PARENT_EXP_RIP}

 test ${POST_PROC:-f} = t && \
   par=${par}"${s}"pP

 test ${PRINT_GREP_MARK:-f} = t && \
   par=${par}"${s}"pGM

# test ${#PROJECT} -gt 0 && \
#   par=${par}"${s}"project=${PROJECT}

 test ${#PROJECT_TABLE} -gt 0 && \
   par=${par}"${s}"tPr=${PROJECT_TABLE}

 test ${#QA_NCFILE_FLAGS} -gt 0 && \
   par=${par}"${s}"qNF=${QA_NCFILE_FLAGS}

 if [ "${REPLICATED_RECORD}" ] ; then
   # convert array to comma-separated list
   REPLICATED_RECORD="${REPLICATED_RECORD[*]}"
   par=${par}"${s}"rR="${REPLICATED_RECORD// /,}"
 fi

 # CORDEX
 if [ ${#TABLE_DRS_CV} -gt 0 ] ; then
   par=${par}"${s}"tCV="${TABLE_DRS_CV}"
 elif [ ${#TABLE_CAD} -gt 0 ] ; then
   # back-ward compatibility
   par=${par}"${s}"tCV="${TABLE_CAD}"
 fi

 test ${#TABLE_GCM_NAME} -gt 0 && \
   par=${par}"${s}"tGCM="${TABLE_GCM_NAME}"
 test ${#TABLE_RCM_NAME} -gt 0 && \
   par=${par}"${s}"tRCM="${TABLE_RCM_NAME}"

 # CMIP5
 test ${#TABLE_ATT_REQ} -gt 0 && \
   par=${par}"${s}"tAR=${TABLE_ATT_REQ}
 test ${#TABLE_EXPERIMENT} -gt 0 && \
   par=${par}"${s}"tX=${TABLE_EXPERIMENT}
 test ${#TABLE_FORCING_DESCRIPT} -gt 0 && \
   par=${par}"${s}"tFD=${TABLE_FORCING_DESCRIPT}

 test ${#TABLE_TIME_SCHEDULE} -gt 0 && \
   par=${par}"${s}"tTR=${TABLE_TIME_SCHEDULE}

 test ${#TABLE_VAR_REQ} -gt 0 && \
   par=${par}"${s}"tVR=${TABLE_VAR_REQ}


 test ${TABLE_RELAXED_DIM_CONSTRAINT:-f} = t && \
   par=${par}"${s}"tRDC

 test ${USE_STRICT:-f} = t && \
   par=${par}"${s}"uS

 return
}

##//! Input paramters of the TimeControl class

set_tc_par()
{
  par="TC::0:e=${TIME_LIMIT}"

 return
}

set_X_par()
{
  local tmp

  # construct directives for the exception handling.
  par=X::

  if [ $# -eq 0 ] ; then
    par=${par}0

    test ${#QA_CHECK_LIST} -gt 0 && \
      par=${par}":"cL=${QA_CHECK_LIST}
  else
    par=${par}"$1"

    if [ "${CF_NOTE}" ] ; then
      local saveNOTE
      test ${NOTE} && saveNOTE=( ${NOTE[*]} )
      NOTE=( ${CF_NOTE} )
    fi

    if [ "${CF_NOTE_ALWAYS}" ] ; then
      local saveNOTE_ALWAYS
      test ${NOTE_ALWAYS} && saveNOTE_ALWAYS=( ${NOTE_ALWAYS[*]} )
      NOTE_ALWAYS=( ${CF_NOTE_ALWAYS[*]} )
    fi

    if [ "${CF_NOTE_LEVEL_LIMIT}" ] ; then
      local saveNOTE_LEVEL_LIMIT
      test ${NOTE_LEVEL_LIMIT} && saveNOTE_LEVEL_LIMIT=( ${NOTE_LEVEL_LIMIT[*]} )
      NOTE_LEVEL_LIMIT=( ${CF_NOTE_LEVEL_LIMIT[*]} )
    fi

    test ${#CF_CHECK_LIST} -gt 0 && \
      par=${par}":"cL=${CF_CHECK_LIST}

    # suppress printing of check results
    par=${par}:nCR
  fi

  if [ "${NOTE}" ] ; then
    NOTE="${NOTE[*]}"
    for(( i=0 ; i < ${#NOTE} ; ++i )) ; do
       test "${NOTE:i:1}" = '{' -o "${NOTE:i:1}" = '}' \
          && tmp=${tmp}
       tmp=${tmp}${NOTE:i:1}
    done
    par=${par}":"note="${tmp// /,}"
  fi

  if [ "${NOTE_ALWAYS}" ] ; then
    tmp=
    NOTE_ALWAYS="${NOTE_ALWAYS[*]}"
    for(( i=0 ; i < ${#NOTE_ALWAYS} ; ++i )) ; do
       test "${NOTE_ALWAYS:i:1}" = '{' -o "${NOTE_ALWAYS:i:1}" = '}' \
          && tmp=${tmp}
       tmp=${tmp}${NOTE_ALWAYS:i:1}
    done
    par=${par}":"nA="${tmp// /,}"
  fi

  if [ "${NOTE_LEVEL_LIMIT}" ] ; then
    tmp=
    NOTE_LEVEL_LIMIT="${NOTE_LEVEL_LIMIT[*]}"
    for(( i=0 ; i < ${#NOTE_LEVEL_LIMIT} ; ++i )) ; do
       test "${NOTE_LEVEL_LIMIT:i:1}" = '{' -o "${NOTE_LEVEL_LIMIT:i:1}" = '}' \
          && tmp=${tmp}
       tmp=${tmp}${NOTE_LEVEL_LIMIT:i:1}
    done
    par=${par}":"nLL="${tmp// /,}"
  fi

  test ${saveNOTE} && NOTE=( ${saveNOTE[*]} )
  test ${saveNOTE_ALWAYS} && NOTE_ALWAYS=( ${saveNOTE_ALWAYS[*]} )
  test ${saveNOTE_LEVEL_LIMIT} && NOTE_LEVEL_LIMIT=( ${saveNOTE_LEVEL_LIMIT[*]} )

  return
}

##//! Signal qa-DKRZ to shut down the current session.

##/*!
## qa-DKRZ traps for TERM signals. This is an EMERGENY STOP.
##*/

signalParent()
{
   if [ ${NEVER_BREAK_SESSION:-f} = t ] ; then
     issueMail=t  # always send email
     return
   fi

   if [ "${HOSTNAME}" = "${QA_HOST}" ] ; then
     kill -${1} $PAR_PID &> /dev/null
   else
     ssh ${QA_HOST} kill -${1} $PAR_PID &> /dev/null
   fi
}

terminate()
{
  isTERM=t
  finally
  exit
}

stripSurrounding()
{
   if [ ${1} = str ] ; then
     # map to a different local name
     local s0=${!1}
     stripSurrounding s0 "$2"

     eval $1=\"${s0}\"
     return
   fi

   local str=${!1}

   test ${#str} -eq 0 && return

   local sc=' '  # default
   test $# -gt 1 && sc="$2"

   local i0 i1 j

   # front
   for(( i0=0 ; i0 < ${#str} ; ++i0 )) ; do
     for(( j=0 ; j < ${#sc} ; ++j )) ; do
       if [ "${str:i0:1}" = "${sc:j:1}" ] ; then
         continue 2
       fi
     done

     break
   done

   # back
   for(( i1=${#str}-1 ; i1 >= i0 ; --i1 )) ; do
     for(( j=0 ; j < ${#sc} ; ++j )) ; do
       if [ "${str:i1:1}" = "${sc:j:1}" ] ; then
         continue 2
       fi
     done

     break
   done

   eval $1=\"${str:i0:$(( i1-i0+1))}\"

   return
}

##//! Flow tracing of the session

##/*!
## Just for debugging or efficiency considerations.
##*/

trace()
{
  local ret

  if [ ${FLOW_TRACE:-f} = f ] ; then
    eval $*
    return $?
  fi

  trc_curr_depth=$(( trc_curr_depth + 1 ))

  local i j index str t0 t1 token count

  # estimating trace itself
  t0=$(unixTime.x dec)

  count=0
  while [ $count -lt 5 ] ;  do  # a workaround for erroneous expr exit value
  # find the function name, perhaps embedded
  if expr match "$*" '[[:alpha:]]*=' &> /dev/null ; then
    # variabel=( $(fnctName ...
    token=$( expr match "$1" '[[:alpha:]]*=*[^[:alpha:]]*\([[:alpha:]]\+\)' )
  elif expr match "$*" '[^[:alpha:]]' &> /dev/null ; then
    # $(fnctName ...
    token=$( expr match "$*" '[^[:alpha:]]*\([[:alpha:]]\+\)' )
    test ${#token} -eq 0 && token="$1"
  else
    token="$1"  # a plain function was called
  fi

    count=$(( count + 1 ))
    test ${#token} -gt 1 && break
  done;

  for(( index=0 ; index < ${#trc_name[*]} ; ++index )) ; do
    test ${trc_name[index]} = trc_${token} && break
  done

  if [ ${index} = ${#trc_name[*]} ] ; then
    trc_name[$index]=trc_${token}
    trc_time[$index]=0.
    trc_count[$index]=0
    trc_depth[$index]=$trc_curr_depth
  fi

  t1=$(unixTime.x dec)
  trc_time[0]=\
$(echo "${trc_time[0]} + $t1 - $t0 - $traceCalibTime" \
   | bc -l)
  trc_count[0]=$(( trc_count[0] + 1 ))

  # time measurement of called function
  t0=$(unixTime.x dec)
  eval $*
  ret=$?
  t1=$(unixTime.x dec)

  trc_time[$index]=\
$(echo "${trc_time[$index]} + $t1 - $t0 - $traceCalibTime" | bc -l)
  trc_count[$index]=$(( trc_count[$index] + 1 ))
  trc_depth[$index]=$trc_curr_depth

  trc_curr_depth=$(( trc_curr_depth - 1 ))

  test ${FLOW_TRACE_EXIT:-f} = t && exit

  return $ret
}

traceCalibration()
{
  local prg

  if [ ${HOSTNAME} = surge ] ; then
    prg="${QA_SRC}/bin/unixTime.x dec"
  elif [ ${HOSTNAME:0:3} = liz ] ; then
    prg="${QA_SRC}/bin_l/unixTime.x dec"
  elif [ ${HOSTNAME:0:4} = pass ] ; then
    prg="${QA_SRC}/bin_p/unixTime.x dec"
  elif [ ${HOSTNAME:0:4} = bliz ] ; then
    prg="${QA_SRC}/bin_b/unixTime.x dec"
  else
    echo "traceCalibration: executable unixTime.x not found"
    exit
  fi

  local t0 t1

  traceCalibTime=0
  trc_curr_depth=0

  t0=$( $prg )
  trace :
  t1=$( $prg )

  traceCalibTime=$(echo "${t1} -${t0}" | bc -l)
  traceStartTime=$( $prg )

  return
}

tracePrint()
{
  # part of the elapsed time used in trace itself will be removed

  local i j tab resid sum out total sz
  sum=0.
  out=$EXP_LOGDIR/executor.trace

  total=$(unixTime.x dec)
  total=$(echo "$total - ${traceStartTime}" | bc -l )

  echo -e "Function\t\tdepth\tcount\ttime [s]" > $out
  echo -e "--------\t\t-----\t---------------" >> $out

  sz=${#trc_name[*]}

  # accumulated time [%]
  for(( i=0 ; i < sz ; ++i )) ; do
    # skip secondary processes
    test ${trc_depth[i]} -gt 1 && continue

    sum=$(echo "$sum + ${trc_time[i]}" | bc -l )
  done

  # residual time
  local tmp
  tmp=$(echo "$total - ${sum}" | bc -l )
  trc_time[${#trc_time[*]}]=$tmp

  # elapsed time
  trc_time[${#trc_time[*]}]=${total}

  # position of the decimal point of the accumulated times
  local pre
  pre=0
  for(( i=1 ; i < ${#trc_time[*]} ; ++i )) ; do
     for((j=0 ; j < ${#trc_time[i]} ; ++j )) do
       if [ "${trc_time[i]:j:1}" = '.' ] ; then
         test $j -gt $pre && pre=$j
         break
       fi
     done
  done

  # formatting of the acc. times
  local trm
  trm=6
  for(( i=1 ; i < ${#trc_time[*]} ; ++i )) ; do
     for((j=0 ; j < ${#trc_time[i]} ; ++j )) do
       if [ "${trc_time[i]:j:1}" = '.' ] ; then
         # trim decimal digits
         trc_time[$i]=${trc_time[i]:0:$(( j + trm))}
         local k
         for(( k=0 ; k < pre - j ; ++k )) ; do
           trc_time[$i]=" ${trc_time[i]}"
         done
         break
       fi
     done
  done

  for(( i=1 ; i < sz ; ++i )) ; do
    if [ ${#trc_name[i]} -lt 12 ] ; then
      tab='\t\t\t'
    elif [ ${#trc_name[i]} -lt 20 ] ; then
      tab='\t\t'
    else # [ ${#trc_name[i]} -lt 28 ] ; then
      tab='\t'
    fi

    echo -e -n "${trc_name[i]:4}"    >> $out
    echo -e -n "${tab}${depth[i]}"   >> $out
    echo -e -n "\t${trc_count[i]}"   >> $out
    echo -e    "\t${trc_time[i]}"    >> $out

  done

  echo -e "--------\t\t \t----------------" >> $out
  tab='\t\t'

  echo -e  "residual time${tab}\t\t${trc_time[sz]}" >> $out

  echo -e "elapsed time${tab}\t\t${trc_time[$((sz+1))]}" >> $out
}

##//! Command launcher

##/*!
## Several commands are passed to this launcher making processing
## more robust against interruptions of the file system.
##*/

tryCom()
{
  # leading options:
  # a) return the status after trying:   get_status
  # b) set temporary sleep period:       set_sleep
  # c) set temporary REATTEMPT_LIMIT:    set_limit

  # $*:   command [with args]

  # Examples:
  # 1) tryCom 'eval echo -e qa-DKRZ.${2} >> qwer/qwer'
  # 2) for f in $(tryCom ls -d *) ; do ... ; done
  # 3) tryCom 'eval echo -e qa-DKRZ.${2} >> qwer/qwer'
  # There is a dependency on bash's "noglob" setting

  local i arg tCStatus
  local countAttempts=0
  local n_shift=0

  local limits=$REATTEMPT_LIMIT
  local t_slice=$SLEEP_TIME
  local getStatus=f

  for(( i=1 ; i <= $# ; ++i )) ; do
    arg=${!i}
    if [ "${arg}" = 'get_status' ] ; then
       getStatus=t
       n_shift=$(( n_shift + 1 ))
       continue
    elif [ "${arg:0:10}" = 'set_limit=' ] ; then
       limits=${arg#*=}
       n_shift=$(( n_shift + 1 ))
       continue
    elif [ "${arg:0:10}" = 'set_sleep=' ] ; then
       t_slice=${arg#*=}
       n_shift=$(( n_shift + 1 ))
       continue
    else
      break
    fi
  done

  test ${n_shift} -gt 0 && shift ${n_shift}

  while : ; do
    $* 2> /dev/null # execute the command

    tCStatus=$?
    test $tCStatus -eq 0 && return 0

    # for a configuration defined period
    if [ $((countAttempts++)) -lt $limits ] ; then
       sleep $t_slice
       continue
    fi

    # number of allowed attempts exceeded.

    # it is ok to have failed, so just return
    test ${getStatus} = t && return $tCStatus

    # Try a last time to get the error message.
    local sendText
    sendText="$( $* 2>&1 )"

    # for instance rm returns an error text with embedded ` and '
    sendText=$( echo $sendText | sed 's%`%%g' |sed "s%'%%g")

    local sendSubject
    sendSubject="QA: command failed after reattempts"

    sTxt[0]="3qaExecution: command failed after reattempts"
    log

    sendEMail

    finally
  done
}

##//! Remote command launcher.

##/*!
## If qa-DKRZ and qaExecutor run on different hosts.
## Several commands are passed to this launcher making processing
## more robust against interruptions of the file system.
##*/

tryRemote()
{
  local mySleep isNoSleep isNotify

  mySleep=5
  if [ "${1}" = noSleep ] ; then
    isNoSleep=t
    shift
  fi

  # wait until host is reachable
  while ! callPing ${QA_HOST} ; do
    sleep $(( ++mySleep ))
  done

  # check whether the destination dir is available
  while : ; do
    $*

    if [ $? -eq 0 ] ; then
      return 0
    elif [ ${isNoSleep:-f} = t ] ; then
      return 1
    else
      if [ "${isNotify:-t}" = 't' ] ; then
        isNotify=f
        sTxt[0]="3qaExecution: ssh failed for ${host} $*"
        log
      fi

      sleep 61
    fi
  done

  return 1
}

wait_fnct()
{
  local rPID=$1
  local count=0

  while : ; do

    # skip pipe with a running job
    if ps -p ${rPID} -o pid= &> /dev/null  ; then
      # there is still an active job for this filenameBase
      sleep 1

      if [ $((count++)) -gt ${ZOMBIE_LIMIT} ] ; then
        # terminate too long running, stalled processing
        formatText "ZOMBIE_LIMIT=${ZOMBIE_LIMIT}s was reached: STOP"
        sendEMail

        isDeadLocked=t
        terminate # exit
      fi
    else
      break
    fi

  done

  return
}

##//! Write tracking id to a container-file

##/*!
## The tracking ID is given by a global attribute in each
## netCDF file. Those of successfully checked sub-temporal files
## of a given variable are collected in a file in QA_RESULT/PROJECT/data/...DRS-structure
##*/

writeTrackingID()
{
  local tidFile item
  tidFile=tid_${name}.txt

  # get the tracking_id
  item=$( getNC_att.x $ncFile tracking_id )

  # don't create multiple entries
  if [ -e $tidFile ] ; then
    if grep ${item} $tidFile &> /dev/null ; then
      return
    fi
  fi

  local str
  str="tracking_id=${item}"
  str="${str} file=${ncFile}"
  str="${str} err_code=-1"
  str="${str} date=$(date +'%FT%T')"

  tryCom echo "$str" >> $tidFile
}

##main()
##{

######## main ############

# first line in the individual log-file

trap terminate TERM

# scan for keywords given on the command-line:
# (no regExp handling)
for item in $* ; do
  keyW=${item%%=*}
  eval $keyW="${item#*=}"
done

test ${FLOW_TRACE:-f} = t && traceCalibration

if \
#trace \
init ; then
  exit 0
fi

# action: the quality control
runQA

# clear working space and exit
#trace \
finally

test ${FLOW_TRACE:-f} = t && tracePrint

exit 0

##}
